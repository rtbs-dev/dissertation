# Desire Paths and Spanning Forests

Addressing gaps discussed in the previous section to reach a generative model for network recovery requires careful attention to the generation mechanism for node activations.
While there are many ways we might imagine bipartite data to be be generated, presuming the existence of a dependency graph that _causes_ activation patterns will give us useful ways to narrow down the generative specification.

First, we will investigate the common assumption that pairwise co-occurrences can serve as proxies for measuring relatedness, and how this "gambit of the group" is, in fact, a strong bias toward dense, clique-filled recovered networks.
Because we wish to model our node activations as being _caused_ by other nodes (that they depend on), we draw a connection to a class of models for _spreading_, or, _diffusive processes_.
We outline how random-walks are related to these diffusive  models of graph traversal, enabled by an investigation of the graph's "regularized laplacian" from @Semisupervisedlearning_Avrachenkov2017.
Then we use the implicit causal dependency tree structure of each observation, together with the Matrix Forest Theorem [@MatrixForestTheorem_Chebotarev2006;@Countingrootedforests_Knill2013] to more generally define our generative node activation model.
This leads to a generative model for binary activation data as rooted random spanning forests on the underlying dependency graph.

## The Gambit of the Inner Product 

As we saw repeatedly in @sec-lit-review, networks are regularly assumed to arise from co-occurrences, whether directly as counts or weighted in some way.
This assumption can be a significant a source of bias in the measurement of edges.
_Why_ a flat count of co-occurrence leads to "hairballs" and bias for dense clusters can be related to the use of inner products on node activation vectors. 


### Gambit of the Group

It seems reasonable, when interactions are unobserved, to assume some evidence for all possible interactions is implied by co-occurrence.
However, similar to the use of uniform priors in other types of inference, if we don't have a good reason to employ a fully-connected co-occurrence prior on interaction dependencies, we are adding systematic bias to our inference.
Whether co-occurrence observations can be used to infer interaction networks directly was discussed at length in @Techniquesanalyzingvertebrate_Whitehead1999, where Whitehead and Dufault call this the _gambit of the group_.

> So, consiously or unconsciously, many ethnologists studying social organization makr what might be called the "gambit of the group": the assume that animals which are clustered [...] are interacting with one another and then use membership of the same cluster [...] to define association.

This work was rediscovered in the context of measuring assortativity for social networks,^[Assortativity is, roughly, the correlation between node degree and the degrees of its neighbors.] where the author of @PerceivedAssortativitySocial_Fisher2017 advises that "group-based methods" can introduce sampling bias to the calculation of assortativity, namely, systematic overestimation when the sample count is low. 
 
The general problems with failing to specify a model of what "edges" actually _are_ get analyzed in more depth in @Statisticalinferencelinks_Peel2022.
They include a warning not to naively use correlational measures with a threshold, since even simple 3-node systems will easily yield false positives edges.
Still, it would be helpful for practitioners to have a more explicit mental model of _why_ co-occurence-based models yield systematic bias,  


### Inner-Product Projections and "Clique Bias"

Underlying correlation and co-occurrence models for edge strength is a reliance on inner products between  node occurrence vectors.
They all use gram matrices (or centered/scaled versions of them), which were brought up in @sec-products.
The matrix multiplication performed represents inner products between all pairs of feature vectors.
For $X(i,j)\in\mathbb{B}$, these inner products sum together the times in each observation that two nodes were activated together.


{{< embed ../codefigs/graphs.qmd#fig-stack-outerprod >}}

However, another (equivalent) way to view matrix multiplication is as a sum of outer products
$$
G(j,j') = X^T X = \sum_{i=1}^m X(i,j)X(i,j')= \sum_{i=1}^m \mathbf{x}_i\mathbf{x}_i^T
$$
Those outer products of binary vectors create $m\times m$ matrices that have a 1 in every $i,j$ entry where nodes $i,j$ both occurred, shown in @fig-stack-outerprod.
Each outer product is effectively operating as a $D_i+A_i$ with degrees normalized to 1.
If the off-diagonals can be seen as adjacency matrices, they would strictly represent a clique on nodes activated in the $i$th observation
In this sense, any method that involves transforming or re-weighting a gram matrix, is implicitly believing that the $k$th observation was a _complete graph_.
This is illustrated in @fig-stacked-graphs. 

:::{#fig-stacked-graphs layout="[[1,2]]"  layout-valign="center"}

{{< embed ../codefigs/graphs.qmd#fig-obs-set >}}
{{< embed ../codefigs/graphs.qmd#fig-stack-bow >}}

Inner-product projections as sums of cliques illustrating "clique bias". 
:::

For many modeling scenarios, this paradigm allows practitioners to make a more straight-forward intuition-check: do clique observations _make sense_ here?
When a list of authors for a paper is finished, does that imply that all authors mutually interacted with all others directly to equally arrive at the decision to publish?
This would be similar to assuming the authors might simultaneously enter the same room, look at a number of others (who all look exclusively at each other, as well), and _all at once_ decide to publish together.
In our introduction, we described a more likely scenario we could expect from an observer on the ground: a researcher asks a colleague or two to collaborate, who might know a couple more with relevant expertise, and so on. 


## Networks as Desire Path Density Estimates

Unfortunately, methods based on inner-product thresholding are still incredibly common, in no small part due to how _easy_ it is to create them from occurrence data, regardless of this "clique-bias".
The ability to map an operation onto every observation, e.g. in parallel, and then reduce all the observations into an aggregate edge estimate is a highly desirable algorithmic trait.
This may be a reason so many projection and backboning techniques attempt two re-weight (but retain) the same basic structure, time and again. 

What we need is a way to maintain the ease-of-use of inner-product network creation:

- map an operation onto each observation
- reduce to an aggregate edge guess over all observations

but with a more domain-appropriate operator at the observation level. 

Let's start with replacements for the clique assumption.
There are many non-clique classes of graphs we might believe local interactions occur on: path-graphs, trees, or any number of graphs that reflect the topolgy or mechanism of local interactions in our domain of interest.
 Authors have proposed classes of graphs that mirror human perception of set shapes [RELATIVE NEIGHBORHOOD]^[
  e.g. for dependencies based on perception, such as human decision making tendencies, or causes based on color names.
], or graphs whose modeled dependencies are strictly planar [planar maximally filtered graps]^[
  e.g. when interactions are limited to planar dependencies, like inferring ancient geographic borders.
].
Alternatively, the interactions might be scale free, small-world, trees, or samples from stochastic block models.[CITE] 
In any case, these assumptions provide an explicit way to describe the set of _possible_ interaction graphs we believe our individual observations are sampled from.

### Subgraph Distributions

Let's use the notation from @eq-edge-vectors, such that each observation of nodes $\mathbf{x}_i$ is implicitly derived from a set of activated edges $\mathbf{r_i}$.
To start, our current belief about what overall structure the whole network can take is $G^*=(V,E,B^*)$, where $B^*$ might always return $1$ to start out (the complete graph).
From this, we construct a $B_i$ for each observation. 
Each $\mathbf{x}_i$ will induce a subgraph $g_i = G^*[V_i]$, where $V_i = \{v\in \mathcal{V} | X(i,\mathcal{V})=1\}$, while our domain knowledge takes the form of a constraint on edges, which will induce a family of subgraphs again.
The "family of subgraphs," in general, can't directly use the edge constraint to create $B_i(e,v)=\mathbf{1}_{V_i}(v)\mathbf{1}_{E_i}(e)$, because edges $E_i$ are not directly observed.
Instead, we model them as inducing a family  $\mathcal{C}_i$ belonging to the relevant class of graphs $\mathcal{C}$ on $V$, i.e.

$$
\begin{gathered}
\mathcal{C}_i = \{(V,E,B_i) \in\mathcal{C}|B_i(e,v)=B^*(e,v)\mathbf{1}_{V_i}(v)\mathbf{1}_{E_i}(e)\}\\
E_i\in\{\mathcal{E}\in\mathcal{P}(E)| g_i[\mathcal{E}]\in\mathcal{C}\}
V_i = \{v\in \mathcal{V} | X(i,\mathcal{V})=1\}
\end{gathered}
$${#eq-subgraph-family}^[$\mathcal{P}(A)$ is the _powerset_ of $A$, i.e. the set of all subsets of $A$. ]

In other words, the edges that "caused" to the node activations in a given observation must _together_ belong to a graph that, in turn, belongs to our desired class.

Assuming we can define an associated measure for each $\mu_i(c)$ on $\mathcal{C}_i$, we are able to define a probability distribution over subgraphs in the class.^[
 This is certainly not a trivial assumption, and might either be ill-defined or require techniques like the Gumbel trick[@GradientEstimationStochastic_Paulus2020] to approximate, unless the partition function $\mathbb{Z}$ has a closed form, or $\mu$ is already a probability measure on some $\sigma$-algebra over $\mathcal{C}$.
 Closed-form $\mathcal{Z}$ values on $\mathcal{C}$ are known for a handful of graph classes, such as the space of spanning trees, $\mathcal{C}=\mathcal{T}$.
 However, another way this might be accomplished is through random geometric graphs[CITE], or geometric spanners like Urqhart[CITE] and Relative Neighborhood [CITE] graphs on a "sprinkling" of points that preserves their observed pairwise distances.   
 This is further discussed in @sec-future-hyperbolic.
]
Using notation similar to distributions over spanning trees in @EfficientComputationExpectations_Zmigrod2021: 

$$
\begin{gathered}
p_i(c) = \frac{\mu_i(c)}{\mathbb{Z}_i}\\
\mathbb{Z}_i = \sum_{c\in\mathcal{C}_i} \mu_i(c)
\end{gathered}
$$ {#eq-subgraph-prob}


To further constrain the problem, let us assume that node activation is noiseless: any activated nodes were truly activated, and unactivated nodes were truly inactive (no false negative or false positive activations).^[
 Hidden nodes (unobserved nodes beyond the $n$) are outside the scope of this work, though could potentially be implied for certain structures e.g. when the metric is known to be tree-like.
 @TreeIam_Sonthalia2020 use a greedy embedding that minimizes distortion to estimate the need for added _Steiner_ nodes. 
]
If a set of nodes $V_i\subseteq V$ were observed in the $i$th observation, this assumption narrows the distribution to only the subgraphs $c\in\mathcal{C}^{V_i}$.
This can be represented using the vectorization in @eq-edge-vectors, due to the one-to-one correspondence established, so that 
$$\mathbf{r}_i|\mathbf{x}_i \sim p_i(c) $${#eq-edgevec-prob}

So we may not have an exact vector, but we have established a way to specify a family of edge vectors that could be responsible.
With $p_i(c)$, we also have a mechanism to sample them when a partition function is available (or able to be approximated).

With these mechanics in place, we see the choice of a clique (implied by the inner product) is a trivial application of @eq-edgevec-prob, since that is equivalent to selecting the class of cliques on $V_i$ nodes.
This has only one element ($\|\mathcal{C}_{\text{clique}}\|=1$), there is only 1 possible selection, with probability $p_i(K^{V_i})=1$.  

[ENTROPY?]

<!-- Once an analyst has provided epistemic justification for a _class of graphs_ to model --> 
<!-- We propose that the computationally-efficient inner-product networks can still be used, but could be made far more effective by counting edge observation counts with something more appropriate than cliques. --> 



### Graph Unions as Desire Paths

- given a sample/MLE/MAP from each row's distribution
- Use beta-bernoulli to estimate each edge's parameters, pairise indep. 
- graphs don't really exist, so we won't act like they do
- approximate a network of paved sidewalks as a network of desire paths
- the desirepaths that are "ahead" in foot traffic are the ones we expect to be "paved" irl.
- once traveled, more likely to be traveled again -> arcsine distribution

## Tree & Forest Distributions

The class of diffusive processes we focus on "spread" from one node to another.
If a node is activated, it is able to activate other nodes it is connected to, directly encoding our need for the graph edges to represent that nodes "depend" on others to be activated.
In this case, a node activates when another node it depends on spreads their state to it.
These single-cause activations are equivalent to imagining a random-walk on the dependency graph, where visiting a node activates it.

### Random Walk Activations 
Random walks are regularly employed to model spreading and diffusive processes on networks.
If a network consists of locations, states, agents, etc. as "nodes", and relationships between nodes as "edges", then random walks consist of a stochastic process that "visits" nodes by randomly "walking" between them along connecting edges.
Epidemiological models, cognitive search in semantic networks, stock price influences, website traffic routing, social and information cascades, and many other domains also involving complex systems, have used the statistical framework of random walks to describe, alter, and predict their behaviors. [CITE...lots?]

When network structure is known, the dynamics of random-walks are used to capture the network structure via sampling [LITTLEBALLOFFUR, etc], estimate node importance's[PAGERANK], or predict phase-changes in node states (e.g. infected vs. uninfected)[SIR I think].
In our case, Since we have been encoding the activations as binary activation vectors, the "jump" information is lost---activations are "emitted" for observation only upon the random walker's initial visit. [CITE INVITE]
In many cases, however, the existence of relationships is not known already, and analysts might *assume* their data was generated by random-walk-like processes, and want to use that knowledge to estimate the underlying structure of the relationships between nodes.


- useful tool for analysis of our data: reg laplacian
- interpretations 

### Dependencies as Trees
The whole graph isn't a tree....Every data point is.


{{< embed ../codefigs/graphs.qmd#fig-stack-tree >}}


[GRAPHIC 1 - my data]

[GRAPHIC 2 - infection vector from meta node]




### Matrix Tree and Forest Theorems 

- one from kirchoff
- one from Chebotarv

## Generative Model Specification

![Explanation of the Random Spanning Forest generative model for binary activation observations](../images/random-spanning-forests.png)
- hierarchical model
- marginalize over the root node. 

