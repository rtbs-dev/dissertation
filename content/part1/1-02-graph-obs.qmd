# Incidence through vector representation

To provide a sufficiently rigorous foundation for network recovery from binary occurrence, we will need a rigorous way to represent networks and occurrences that lends itself to building structured ways both connect to each other.
We build on the incidence structure and matrix product formalism from the previous chapter, introducing various ways to build graphs as incidence structures that have direct representations as matrices.
This can be extended to representing occurrences as matrices of _hyperedge vectors_.
This view allows us to interpret different representations of graphs (or hypergraphs) as connected by simple matrix operations.

 
Traditionally[@MathematicalfoundationsGraphBLAS_Kepner2016;@WhyHowWhen_Torres2021], we might say a graph on nodes (or, "vertices") $v\in V=\{1,\cdots,n\}$ and "edges" $E$ is a tuple:
$$
G=(V,E) \quad \textrm{s.t.} \quad E\subseteq V \times V
$$

The _adjacency matrix_ $A$ of $G$, degree matrix $D$, and graph/discrete Laplacian $L$ are then defined as:^[
 The _indicator function_ $\mathbf{1}_A(x)$ is 1 for values of $x$ in the set $A$, and 0 otherwise.
] 
$$
\begin{aligned}
A(u,v) & =\mathbf{1}_E((u,v)) \quad &A : V\times V\rightarrow \mathbb{B} \\
D(u,v) & =\mathrm{diag}({\textstyle\sum}_V A(u,v))\quad &D : V\times V\rightarrow \mathbb{N} \\
L(u,v) & = D(u,v) - A(u,v) \quad &L : V\times V\rightarrow \mathbb{Z} 
\end{aligned}
$$

However, if edges and their recovery is so important to us, defining them explicitly as pairs of nodes can be problematic when we wish to estimate their existence (or not) when pairs of nodes co-occur.
Additionally, we have to be very careful to distinguish whether our graph is _(un)directed_, _weighted_, _simple_, etc., and hope that the edge set has been filtered to a subset of $N\times N$ for each case.
Instead, we propose a less ambiguous framework for vectorizing graphs, based on their underlying incidence structure.

## Graphs as incidence structures

 Instead, we give edges their own set of identifiers, $e\in E=\{1,\cdots \omega\}$.
 Now, define graphs as incidence structures between nodes and edges such that every edge is incident to either two nodes, or none:

$$
G = (V,E,\mathcal{I}) \quad s.t. \quad \mathcal{I} \subseteq E\times V
$$ {#eq-simple-incidence}

Variations on graphs can often be conveniently defined as constraints on $\mathcal{I}$:

- Self loops can be prohibited by only allowing unique flags for a given relation^[
 never two flags with the same pair, i.e. $\mathcal{I}$ is a set, not a multiset.
]
- Multigraphs are similarly described by whether we allow pairs of vertices to appear with more than one edge^[
 in the set of flags containing nodes $u$ or $v$, only one $e$ may be incident to both of them.
]

Together, these constraints define "simple" graphs. 
Similarly, we can equip @eq-simple-incidence with a function $B$ that allows $\mathcal{I}$ to encode information about the specific kinds of incidence relations under discussion.
We give $B$ a range of possible flag values $S$:


$$
G = (V,E,\mathcal{I},B) \quad s.t. \quad \mathcal{I} \subseteq E\times V\quad B:\mathcal{I}\rightarrow S
$$ {#eq-map-incidence}

- Undirected, unweighted graphs only need single elements: "incidence exists" i.e.$S=\{1\}$
- Directed graphs can use two elements e.g. a "spin" for $S=\{-1,1\}$
- Weighted, undirected graphs are supported on positive scalars e.g. $S=\mathbb{R}^+$
- Weighted, directed graphs are supported on any scalar e.g. $S=\mathbb{R}_{\neq0}$

If the "absence" of incidence needs to be modeled explicitly, a "null" stand-in (0,False) can be added to each $S$, which is useful for representing each structure as arrays for use with linear algebra (i.e. $\{0,1\}$,$\{-1,0,-1\}$,$\mathbb{R}^+_0$, and $\mathbb{R}$, respectively).
By doing so, we can also place an exact limit on the maximum possible size of $\omega=\|E\|$ in the simple graph case, and indicate edges by their unique ID, such that $\mathcal{I}= E\times V$ is no longer a subset relation for $E=\{1,\cdots,{n\choose2} \}$.
Instead of existence in $\mathcal{I}$, we explicitly use incidence relation $S$ to tell us whether each possible edge "exists" or not, simplifying our graph definition further^[
 if we allow multi-edges, then 
]:

  
$$
\begin{aligned}
G  = (V,E,B) \quad s.t. \quad & B : E\times V \rightarrow S\\
& v \in V = \{1,\cdots, n\}\quad \\
& e \in E = \left\{1,\cdots, {n\choose 2} \right\}
\end{aligned}
$$ {#eq-incidence-graph}




The representation of $B$ in @eq-incidence-graph bears a remarkable similarity to our original description of design matrices in @eq-design-mat. 
In fact, as a matrix, $B(e,v)$ is called the _incidence_ matrix: every row has two non-zero entries, with every column containing a number of non-zero entries equal to that corresponding node's degree in $G$.
Traditionally, we use an _oriented_ incidence matrix, such that each row has exactly one positive (non-zero) value, and one negative (non-zero) value.^[
  In fact, this would make B^*(v,e) equivalent to a _graphical matroid_, another common formalism that generalizes graph-like structures to vector space representations.
]
Even for undirected graphs, the selection of _which entry_ is positive or negative is left to be ambiguous, since much of the math used later is symmetric w.r.t. direction^[though not always!]. 

### Embedding incidences in vector space

A formalism for graphs that starts with incidence matrices would benefit from a _canonical_ oriented incidence matrix, rather than the family that is ambiguous w.r.t. edge orientation.
To start, we can be more precise by selecting each row(edge) vector, and partitioning it into two: one for each non-zero column (node) that edge is incident to.
Every incidence can be represented individually as standard basis vector $\mathbf{e}$ in the feature space of $B$, scaled by the corresponding value of $S$.

Let $V_e$ be the set of nodes with (non-zero) incidence to edge $e$.
Then the incidence vectors are:  
$$\delta_e(v) = B(e,v)\mathbf{e}_v \quad \forall v\in V_e$${#eq-incidence-vec}
And the (unoriented) incidence matrix vectors are recovered as sums over the incidence vectors for each edge:
$$\mathbf{b}^+_e = \sum_{v\in V_e} \delta_e(v)$${#eq-incidence-edge-sum}

A traditional approach might then define undirected graphs as equivalent, in some sense, to multidigraphs, where each edge is really two directed edges, in opposing directions.
This does allow the matrix $B$ to have the correct range for its entries in this formalism (the directed graph range, $S=\{-1,0,1\}$), and the edge identity  based on sums would hold. 
However, the resulting set of incidences would have twice the number of edges than our combinatoric limit for simple graphs, and prevent the more elegant definition of graph types through the set $\mathbf{S}$.
Plus, it would necessitate averaging of weights over different edge ID's to arrive at a single undirected "edge weight", and many other implementation details that make keeping track of specifics difficult for practitioners.

Instead, we would like a canonical oriented distance matrix, which can be derived from the vectorized incidences in the undirected range of $B$ (the standard basis vectors).
Without loss of generality, let $u_e,v_e\in V_e$ be nodes such that $u<v$.^[the inequality is strict because self-loops are not allowed.]
Using this, we can unambiguously define a _partition_ $B(e,\cdot)=B(e,u_e) + B(e,v_e)$ between incidences on $e$, along with a new derived incidence, $B_o$, which has oriented rows like:
$$B_o(e,\cdot)=\mathbf{b}^o_e = \delta_e(u)-\delta_e(v)$$
In other words, while the unoriented incidence matrix is the "foundational" representation for graphs in our formalism, the (canonical) oriented one can be derived, even if negative incidence values are not in $\mathbb{S}$.^[
 This works as long as we are in at least a ring, since semirings in general do not need to define additive inverse operations.
 In this case we would limit ourselves to the oriented incidence.
]

But, now that we have removed the information on "which nodes an edge connects" from our definition of edges (since every edge is a scalar ID), how do we construct $V_e$ without a circular dependency on $B$ to find non-zero entries?
Because of our unique identification of edges up to the combinatoric limit, we can still actually provide a unique ordering of the nodes in $V_e$, without searching over the entirety of $B$'s domain.
Using an identity from @ParallelEuclideandistance_Angeletti2019, we have a closed-form equation both to retrieve the IDs of nodes $u,v$ (given an edge $e$), and an edge $e$ (given two nodes $u,v$), for any simple graph with $n$ vertices.
$$
\begin{aligned}
    u_n(e) & = n - 2 - \left\lfloor\frac{\sqrt{-8e + 4n(n - 1) - 7}-1}{2}\right\rfloor\\
    v_n(e) & = e + u_n(e) + 1 -\frac{1}{2} \left(n (n - 1) + (n - u_n(e))^2 - n+u_n(e)\right)\\
    e_n(u,v) & = \frac{1}{2}\left(n(n - 1) - ((n - u)^2 - n+u)\right) + v - u - 1
\end{aligned}
$$ {#eq-sq-id}
Our ease-of-calculation lets us drop some of the excess notation and refer to our (un)oriented incidence matrices in terms of the incidences of each edge on their $u$ or $v$, directly.
$$
B = B_u + B_e \qquad B_o \equiv B_u - B_v
$$

<!-- ![Edge Relation Observational Model](../images/relation-observations.png) -->

### Inner products on $B$

With all of this background, the other representations of graphs can seen as derivations from the canonical incidence matrices. 
The Laplacian, which is usually introduced either in terms of ajacency/degree, or as the gram matrix for orineted edge vectors, is also a squared distance matrix between all pairs of incidences on $(u,v)$.
The other identities are simply consequences of the polarization identity, since the Laplacian is the also defined as the gram matrix on oriented incidence vectors: 
$$
\begin{split}
L & = B_o^TB_o\\
  & = \|B_u - B_v \|^2 \\
  & = 2\|B_u\|^2 +2\|B_v\|^2 - \|B_u + B_v \|^2 \\
  & = 2D - B^TB = D-A
\end{split}
$${#eq-laplacian}
@eq-sq-distance

We take such pains taken to derive the traditional graph objects because it goes to show how fundamental the _incidences_ are as units of observation.
Unlike @eq-sq-distance, @eq-laplacian is a distance between two distinct sets of incidences ($e$ on $u$,  ) (not all pairwise combinations within a set). 
Laplacians are therefore sub-matrices of a larger distance matrix, where each incidence vector is a single standard basis vector, or put another way, _gram matrix_ over incidences
$$
G_{\mathcal{I}}=
\begin{bmatrix} B_u & B_v \end{bmatrix}\begin{bmatrix}B_u\\B_v\end{bmatrix}
$$
contains the laplacian in the off-diagonal blocks. 
Laplacian as inner product on incidence observations.
Associated objects (degree vector, o)

Rescaling to achieve normaalization.

Use to define kernels (and application e.g. soft-cosine measure)

...

### Metrological Considerations: Interaction Vectors 

TODO

Strictly speaking, we can't say that nodes are directly observed in this space... edges are.
Collections of nodes are measured two-at-a-time (one-per-edge being traversed).

Another way to approach is to view inner products as a sum of outer products.
A each edge uniquely corresponds to 2 nodes (in a simple graph).
Use triangle unfolding for closed form bijection.

Unrolling 3D tensor of subgraphs along eads to a secondary representation of graphs as an _edgelist_, having binary activation vectors on edges rather than nodes.
Then each observation in this model is necessarily a set of activated edges.
The non-zero (visited) nodes are found using the incidence matrix as an operator. 


## Graphs and node occurrences 

TODO

![Hyperedge Relation Observational Model](../images/hypergraph-observations.png)

### Hyperedges as vectors of node occurrence


::::{#fig-incidence-struct layout="[[1,1]]"}

::: {#fig-biadj-mat}
$$
%X(\{1,2,3,4,\cdots\})=\\
\begin{array}{c c}
& \begin{array}{cccccccccc} a & b & c & d & e & f & g & h & i & j\\ \end{array} \\
\begin{array}{c c } x_1\\x_2\\x_3\\x_4\\ \vdots \end{array} &
\left[
\begin{array}{c c c c c c c c c c}
  0  &  0  &  1  &  0  &  1  &  0  &  1  &  1  &  0  &  0 \\
  1  &  0  &  0  &  0  &  1  &  1  &  0  &  0  &  0  &  0 \\
  0  &  1  &  0  &  0  &  0  &  1  &  0  &  0  &  1  &  1 \\
  0  &  0  &  0  &  1  &  1  &  0  &  0  &  1  &  0  &  0 \\
  &&&& \vdots &&&&&
\end{array}
\right]
\end{array}
$$

:::

{{< embed ../codefigs/graphs.qmd#fig-bipartite >}}

::::


### Inner product on Hyperedges
Roundabout way of describing binary/occurrence data.
Inner product is co-occurrences.

Leads to correlation/covariance, etc. 


### Combining Occurrence & Dependence

- soft cosine
- kernels on graphs (incl. coscia euclidean)
- Retrieving one from the other is hard. 

