<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Metrology with matrices – Measuring Network Dependencies from Node Activations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../content/part1/1-02-graph-obs.html" rel="next">
<link href="../../content/00-intro.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6d9f7168ccb3133a0c0fd8fac57d4f56.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/part1/1-01-matrix-meas.html">A Practitioner’s Guide to Network Recovery</a></li><li class="breadcrumb-item"><a href="../../content/part1/1-01-matrix-meas.html"><span class="chapter-title">Metrology with matrices</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Measuring Network Dependencies from Node Activations</a> 
        <div class="sidebar-tools-main">
    <a href="../../Measuring-Network-Dependencies-from-Node-Activations.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/00-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">A Practitioner’s Guide to Network Recovery</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-01-matrix-meas.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Metrology with matrices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-02-graph-obs.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Vector representations of incidence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-03-recovery-road.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Roads to Network Recovery</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Nonparametric Network Recovery With Random Spanning Forests</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-04-rand-sf.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Latent Graphs with Desire Paths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-05-forest-pursuit.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Approximate Recovery in Near-linear Time by <em>Forest Pursuit</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-06-latent-forest-alloc.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Modifications &amp; Extensions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Applications &amp; Case Studies</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part3/3-07-qualitative.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Qualitative Application of Relationship Recovery</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part3/3-08-ordered.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Recovery from Working Memory &amp; Partial Orders</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/09-conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Conclusion &amp; Future Work</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-matrix-notation" id="toc-sec-matrix-notation" class="nav-link active" data-scroll-target="#sec-matrix-notation">Observation and feature “spaces”</a></li>
  <li><a href="#sec-lin-ops" id="toc-sec-lin-ops" class="nav-link" data-scroll-target="#sec-lin-ops">Models &amp; linear operators</a></li>
  <li><a href="#sec-smooth-err" id="toc-sec-smooth-err" class="nav-link" data-scroll-target="#sec-smooth-err">Measurement quantification &amp; error</a>
  <ul class="collapse">
  <li><a href="#sec-counting" id="toc-sec-counting" class="nav-link" data-scroll-target="#sec-counting">Additive Smoothing</a></li>
  <li><a href="#conditional-probabilities-contingencies" id="toc-conditional-probabilities-contingencies" class="nav-link" data-scroll-target="#conditional-probabilities-contingencies">Conditional Probabilities &amp; Contingencies</a></li>
  </ul></li>
  <li><a href="#sec-products" id="toc-sec-products" class="nav-link" data-scroll-target="#sec-products">Distance vs.&nbsp;Incidence</a>
  <ul class="collapse">
  <li><a href="#kernels-distances" id="toc-kernels-distances" class="nav-link" data-scroll-target="#kernels-distances">Kernels &amp; distances</a></li>
  <li><a href="#incidence-structures-dependency" id="toc-incidence-structures-dependency" class="nav-link" data-scroll-target="#incidence-structures-dependency">Incidence structures &amp; dependency</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/part1/1-01-matrix-meas.html">A Practitioner’s Guide to Network Recovery</a></li><li class="breadcrumb-item"><a href="../../content/part1/1-01-matrix-meas.html"><span class="chapter-title">Metrology with matrices</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Metrology with matrices</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p>Where metrology is concerned, the actual unit of observation and how it is encoded for us is critical to how analysts may proceed with quantifying, modeling, and measuring uncertainty around observed phenomena. Experiment and observation tends to be organized as inputs and outputs, or, independent variables and dependent variables, specifically. Independent variables are observed, multiple times (“observations”), and changes in outcome for each can be compared to the varying values associated with the independent variable input (“features”). For generality, say a practitioner records their measurements as scalar values, i.e.&nbsp;<span class="math inline">\(x\in\mathbb{S}\in\{\mathbb{R,Z,N},\cdots\}\)</span>. The structure most often used to record scalar values of <span class="math inline">\(n\)</span> independent/input variable features over the course of <span class="math inline">\(m\)</span> observations is called a design matrix <span class="math inline">\(X:\mathbb{S}^{m\times n}\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp; Not all observations are scalar, but they can become so. If individual measurements are higher-dimensional (e.g.&nbsp;images are 2D), X is a tensor, which can be transformed through unrolling or embedding into a lower dimensional representation before proceeding. There are other techniques for dealing with e.g.&nbsp;categorical data, such as one-hot encoding (where the features are binary for each possible category, with boolean entries for each observation).</p></div></div><section id="sec-matrix-notation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-matrix-notation">Observation and feature “spaces”</h2>
<p>If we index a set of observations and features, respectively, as <span class="math display">\[ i\in I=\{1,\cdots,m\}, \quad j\in J=\{1,\cdots,n\},\qquad I,J:\mathbb{N}\]</span> then the design matrix can map the index of an observation and a feature to the corresponding measurement. <span id="eq-design-mat"><span class="math display">\[
x=X(i,j)\qquad X : I\times J \rightarrow \mathbb{S}
\tag{2.1}\]</span></span> i.e.&nbsp;the measured value of the <span class="math inline">\(j\)</span>th independent variable from the <span class="math inline">\(i\)</span>th observation.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In this scheme, an “observation” is a single row vector of features in <span class="math inline">\(\mathbb{S}^{n\times 1}\)</span> (or simply <span class="math inline">\(\mathbb{S}^{n}\)</span>), such that each observation encodes a position in the space defined by the features, i.e.&nbsp;the <em>feature space</em>, and extracting a specific observation vector <span class="math inline">\(i\)</span> from the entire matrix can be denoted as <span class="math display">\[\mathbf{x}_i=X(i,\cdot),\quad \mathbf{x}:J\rightarrow\mathbb{S}\]</span> Similarly, every “feature” is associated with a single column vector in <span class="math inline">\(\mathbb{S}^{1\times m}\)</span>, which can likewise be interpreted as a position in the space of observations (the <em>data space</em>): <span class="math display">\[\mathbf{x}_j'=X(\cdot,j),\quad \mathbf{x}':I\rightarrow\mathbb{S}\]</span> Note that this definition could be swapped without loss of generality. In other words, <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{x}'\)</span> being in row and column spaces is somewhat arbitrary, having more to do with the logistics of experiment design and data collection. We could have measured our feature vectors one-at-a-time, measuring their values over an entire “population”, in effect treating that as the independent variable set.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp; This notation is adapted from the sparse linear algebraic treatment of graphs in <span class="citation" data-cites="GraphAlgorithmsLanguage_Kepner2011"><a href="#ref-GraphAlgorithmsLanguage_Kepner2011" role="doc-biblioref">[1]</a></span> and <span class="citation" data-cites="MathematicalfoundationsGraphBLAS_Kepner2016"><a href="#ref-MathematicalfoundationsGraphBLAS_Kepner2016" role="doc-biblioref">[2]</a></span>. </p><div id="ref-GraphAlgorithmsLanguage_Kepner2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">J. Kepner and J. Gilbert, <em>Graph algorithms in the language of linear algebra</em>. Philadelphia: Society for Industrial; Applied Mathematics, 2011.</div>
</div><div id="ref-MathematicalfoundationsGraphBLAS_Kepner2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">J. Kepner <em>et al.</em>, <span>“Mathematical foundations of the <span>GraphBLAS</span>,”</span> in <em>2016 <span>IEEE</span> high performance extreme computing conference (<span> HPEC</span>)</em>, Sep. 2016, pp. 1–9. doi: <a href="https://doi.org/10.1109/HPEC.2016.7761646">10.1109/HPEC.2016.7761646</a>.</div>
</div></div><div id="fn3"><p><sup>3</sup>&nbsp; In fact, vectors are often said to be in the column-space of a matrix, especially when using them as transformations in physics or deep learning layers. We generally follow a one-observation-per-row rule, unless otherwise stated.</p></div></div><p>To illustrate this formalism in a relevant domain, let’s take another look at co-citation networks. For <span class="math inline">\(m\)</span> papers we might be aware of <span class="math inline">\(n\)</span> total authors. For a given paper, we are able to see which authors are involved, and we say those authors “activated” for that paper. It makes sense that our observations are individual papers, while the features might be the set of possible authors. However, we are not given information about which author was invited by which other one, or when each author signed on. In other words, the measured values are strictly boolean, and we can structure our dataset as a design matrix <span class="math inline">\(X:\mathbb{B}^{m\times n}\)</span>. We can then think of the <span class="math inline">\(i^{\mathrm{th}}\)</span> paper as being represented by a vector <span class="math inline">\(\mathbf{x}_i:\mathbb{B}^n\)</span>, and proceed using it in our various statistical models. If we desired to analyze the set of authors, say, in order to determine their relative neighborhoods or latent author communities, we could equally use the feature vectors for each paper, this time represented in a vector <span class="math inline">\(\mathbf{x}'_j:\mathbb{B}^{1\times m}\)</span>.</p>
</section>
<section id="sec-lin-ops" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-lin-ops">Models &amp; linear operators</h2>
<p>Another powerful tool an analyst has is <em>modeling</em> the observation process. This is relevant when the observed data is hypothesized to be generated by a process we can represent mathematically, but we do not know the parameter values to best represent the observations (or the observations are “noisy” and we want to find a “best” parameters that account for this noise). This is applicable to much of scientific inquiry, though one common use-case is the de-blurring of observed images (or de-noising of signals), since we might have a model for how blurring “operated” on the original image to give us the blurred one. We call this “blurring” a <em>linear operator</em> if it can be represented as a matrix<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, and applying it to a model with <span class="math inline">\(l\)</span> parameters is called the <em>forward map</em>: <span class="math display">\[\mathbf{x} = F\mathbf{p}\qquad F:\mathbb{R}^{l}\rightarrow \mathbb{R}^n\]</span> where <span class="math inline">\(P\)</span> is the space of possible parameter vectors, i.e.&nbsp;the <em>model space</em>. The forward map takes a modeled vector and predicts a location in data space.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;in the finite-dimensional case</p></div></div><p>Of critical importance, then, is our ability to recover some model parameters from our observed data, e.g.&nbsp;if our images were blurred through convolution with a blurring kernel, then we are interested in <em>deconvolution</em>. If <span class="math inline">\(F\)</span> is invertible, the most direct solution might be to apply the operator to the data, as the <em>adjoint map</em>: <span class="math display">\[ \mathbf{p} = F^H\mathbf{x}\qquad F^H:\mathbb{R}^{n}\rightarrow \mathbb{R}^l\]</span> which removes the effect of <span class="math inline">\(F\)</span> from the data <span class="math inline">\(\mathbf{x}\)</span> to recover the desired model <span class="math inline">\(\mathbf{p}\)</span>.</p>
<p>Trivially we might have an orthogonal matrix <span class="math inline">\(F\)</span>, so <span class="math inline">\(F^H=F^{-1}\)</span> is available directly. In practice, other approaches are used to minimize the <em>residual</em>: <span class="math inline">\(\hat{\mathbf{p}}^=\min_{\mathbf{p}} F\mathbf{p}-\mathbf{x}\)</span>. Setting the gradient to 0 yields the normal equation, such that <span class="math display">\[ \hat{\mathbf{p}}=(F^TF)^{-1}F^T\mathbf{x}\]</span> This should be familiar to readers as equivalent to solving ordinary least-squares (OLS). However, in that case it is more often shown as having the <em>design matrix</em> <span class="math inline">\(X\)</span> in place of the operator <span class="math inline">\(F\)</span>.</p>
<p><em>This is a critical distinction to make:</em> OLS as a “supervised” learning method treats some of the observed data we represented as a design matrix previously as a target to be modeled, <span class="math inline">\(y=X(\cdot,j)\)</span>, and the rest maps parameters into data space, <span class="math inline">\(F=X(\cdot,J/j)\)</span>. With this paradigm, only the target is being “modeled” and the rest of the data is used to create the operator. In the citation network example, it would be equivalent to trying to predict one variable, like citation count or a specific author’s participation in every paper, <em>given</em> every other author’s participation in them.</p>
<p>For simplicity, most work in the supervised setting treats the reduced data matrix as X, opting to treat <span class="math inline">\(y\)</span> as a separate <em>dependent variable</em>. However, our setting will remain <em>unsupervised</em>, since no single target variable is of specific interest—all observations are “data”. In this, we more closely align with the deconvolution literature, such that we are seeking a model and an operation on it that will produce the observed behavior in an “optimal” way.</p>
</section>
<section id="sec-smooth-err" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-smooth-err">Measurement quantification &amp; error</h2>
<p>In binary data, such as what we have been considering, it is common to model observables as so-called “Bernoulli trials”: events with two possible outcomes (on, off; yes, no; true, false), and one outcome has probability <span class="math inline">\(p\)</span>. These can be thought of as weighted coin-flips: “heads” with probability <span class="math inline">\(p\)</span>, and “tails” <span class="math inline">\(1-p\)</span>. If <span class="math inline">\(k\)</span> trials are performed (the “exposure”), we say the number of successes <span class="math inline">\(s\)</span> (the “count”) is distributed as a binomial distribution <span class="math inline">\(s\sim Bin(p,k)\)</span>. The empirical estimate for the success probability is <span class="math inline">\(\hat{p}=\tfrac{s}{k}\)</span>.</p>
<p>Note that this naturally resembles marginal sums on our design matrix <span class="math inline">\(X\)</span>, if we treat columns (or rows!) as an array of samples from independent Bernoulli trials: <span class="math inline">\(\hat{p}_j = \frac{\sum_{i\in I} X(i,j)}{m}\)</span>. Many probability estimates involving repeated measurements of binary variables (not simply the row/column variables) have this sort of <span class="math inline">\(\frac{\textrm{count}}{\textrm{exposure}}\)</span> structure, as will become useful in later sections.</p>
<p>However, if we are “measuring” a probability, we run into issues when we need to quantify our uncertainty about it. For instance, an event might be quite rare, but if in our specific sample we <em>never</em> see it, we still do not generally accept a probability of zero.</p>
<section id="sec-counting" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-counting">Additive Smoothing</h3>
<p>One approach to dealing with this involves adding <em>pseudocounts</em> that smooth out our estimates for count/exposure, from which we get the name “additive smoothing”.[CITE?] <span class="math display">\[\hat{p} = \frac{s+\alpha}{k+2\alpha} \]</span> Adding 1 success and 1 failure (<span class="math inline">\(\alpha=1\)</span>) as pseudocounts to our observations is called <em>Laplace’s Rule of Succession</em>, or simply “Laplace smoothing,”<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> while adding <span class="math inline">\(\alpha=0.5\)</span> successes and failures is called using <em>Jeffrey’s Prior</em>. It’s so-called because this pseudocount turns out to be a special case of selecting a Beta prior on the Bernoulli probability <span class="math inline">\(p\sim \textrm{Beta}(\alpha, \beta)\)</span>, such that the posterior distribution for <span class="math inline">\(p\)</span> after our observations is <span class="math inline">\(\textrm{Beta}(s+\alpha, k-s+\beta)\)</span>, which has the mean: <span id="eq-beta-binomial"><span class="math display">\[
E[p|s,k]=\frac{s+\alpha}{k-\alpha+\beta}
\tag{2.2}\]</span></span></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp; derived when Laplace desired estimates of probability for unobserved phenomena, such as the sun (not) rising tomorrow.</p></div><div id="fn6"><p><sup>6</sup>&nbsp; A useful comparison of the two priors (1, 0.5) is to ask, given all of the trials we have seen so far, whether we believe we are near the “end” or “middle” of an average run of trials. For <span class="math inline">\(\alpha=1\)</span>, we believe nearly all evidence has been collected, but for <span class="math inline">\(\alpha=0.5\)</span>, only half of expected evidence has been observed.<br>
</p></div></div><p>This exactly recovers additive smoothing with a Jeffrey’s prior for <span class="math inline">\(\alpha=\beta=0.5\)</span>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> This generalization allows us to be more flexible, and specify our prior expectations on counts or exposure with more precision. Such models provide both an estimate of the aleatory uncertainty (via the posterior distribution), and a form of “shrinkage” that prevents sampling noise from unduly affecting parameter estimates (via the prior distribution). Despite being a simple foundation, this treatment of “counts” and “exposure” can be built upon in many ways.</p>
</section>
<section id="conditional-probabilities-contingencies" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="conditional-probabilities-contingencies">Conditional Probabilities &amp; Contingencies</h3>
<p>In dependency/structure recovery, since our goal involves estimating (at least) pairwise relationships, the independence assumption required to estimate node occurrences as Beta-Binomial is clearly violated.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp; In fact, a recent method from <span class="citation" data-cites="MultivariateBernoullidistribution_Dai2013"><a href="#ref-MultivariateBernoullidistribution_Dai2013" role="doc-biblioref">[3]</a></span> models probabilistic binary observations, <em>with dependencies</em>, by generalizing the mechanics overviewed here to a fully multivariate Bernoulli distribution, capable of including 3rd- and higher-order interractions, not just pairwise.<br>
</p><div id="ref-MultivariateBernoullidistribution_Dai2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">B. Dai, S. Ding, and G. Wahba, <span>“Multivariate bernoulli distribution,”</span> <em>Bernoulli</em>, vol. 19, no. 4, Sep. 2013, doi: <a href="https://doi.org/10.3150/12-bejsp10">10.3150/12-bejsp10</a>.</div>
</div></div></div><p>However, it’s common to estimate how similar two random variables <span class="math inline">\(A,B\)</span> are, e.g.&nbsp;if samples of each correspond to columns of binary <span class="math inline">\(X\)</span>. For instance, the joint probabilities <span class="math inline">\(P(A\cap B)\)</span> answer “how often does A happen with B, out of all data?” Conditional probabilities <span class="math inline">\(P(A|B)=\frac{P(A\cap B)}{P(B)}\)</span> measure how often A occures given B happened. Once again, we can estimate the base probabilities <span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span> with methods like <a href="#eq-beta-binomial" class="quarto-xref">Equation&nbsp;<span>2.2</span></a> for each marginal sums <span class="math inline">\(X(\cdot,A)\)</span> or <span class="math inline">\(X(\cdot,B)\)</span>, but the joint and conditional probabilities can instead be estimated using matrix multiplication using the Gram matrix, discussed below. It encodes pair-wise co-occurrence counts, such that <span class="math inline">\(G(i,i'):\mathbb{Z}^{n\times n}\)</span> has the co-occurrence count for node <span class="math inline">\(i\)</span> with <span class="math inline">\(i'\)</span>.</p>
<p>For binary data, we typically create association meatures from values on a <span class="math inline">\(2\times2\)</span> contingency table, with counts and marginals. A shorthand notation for these values is:</p>
<p><span id="eq-contingency"><span class="math display">\[
\begin{array}{c|cc|c}
      &amp; B=1         &amp; B=0         &amp; \sum_B \\
\hline
A=1   &amp; p_{11}      &amp; p_{10}      &amp; p_{1\bullet} \\
A=0   &amp; p_{01}      &amp; p_{00}      &amp; p_{0\bullet} \\
\hline
\sum_A   &amp; p_{\bullet 1} &amp; p_{\bullet 0} &amp; p_\bullet \\
\end{array}
\tag{2.3}\]</span></span></p>
<p>The co-occurrence probability <span class="math inline">\(p_{11}=P(A\cap B)\)</span> for each pair can also be approximated with the beta-binomial scheme mentioned above, but care must be taken not to confuse this with the edge strength connecting two nodes. First, nodes that rarely activate (low node probability) may nonetheless reliably connect to others when they do occur (high edge probability). In fact, without direct observation of edges, we are not able to estimate their count, <em>or</em> their exposure, which can be a source of systemic error from <em>epistemic uncertainty</em>. We don’t know when edges are used, directly, and we also don’t have a reliable way to estimate the opportunities each edge had to activate (their exposure), either. This is especially true when we wish to know whether an edge even <em>can</em> be traversed, i.e.&nbsp;the edge <em>support</em>. Support, as used in this sense, is the set of inputs for which we expect a non-zero output. Intuitively, this idea captures the sense that we might care more about <em>whether</em> an edge/dependency exists, not <em>how important</em> it is. For that, we have to re-assess our simple model: even if we could count the number of times an edge might have been traversed, how do we estimate the opportunities it had to be available for traversal (it’s “exposure”)?</p>
<p>Assuming this kind of epistemic uncertainty can be adequately addressed through modeling—attempts at which will be discussed in more detail in <a href="1-03-recovery-road.html" class="quarto-xref"><span>Roads to Network Recovery</span></a>—conditional probability/contingency tables will again be useful for validation. When comparing estimated edge probability to some known “true” edge existence (if we have that), we can count the number of correct predictions, as well as type I (false positive) and type II (false negative) errors. We can do this at <em>every probability/weight threshold value</em>, as well, and we will return to ways to aggregate all of these values into useful scoring metrics in <a href="../part2/2-05-forest-pursuit.html#sec-FP-experiments" class="quarto-xref"><span>Simulation Study</span></a>.</p>
</section>
</section>
<section id="sec-products" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-products">Distance vs.&nbsp;Incidence</h2>
<p>As we have already seen, operations from linear algebra make many counting and combinatoric tasks easier, while unifying disparate concepts to a common set of mechanics. In addition to having a map from integer indices to sets of interest, these design matrices/vectors are implicitly assumed to have entries that exist in a field <span class="math inline">\(F=(\mathbb{S},\oplus,\otimes)\)</span>. equipped with operators analogous to addition (<span class="math inline">\(\oplus\)</span>) and multiplication (<span class="math inline">\(\otimes\)</span>).<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> With this, we are able to define generalized inner products that take pairs vectors in a vector space <span class="math inline">\(\mathbf{x}\in V\)</span>, such that <span class="math inline">\(\langle\cdot,\cdot\rangle_F:\mathbb{S}^n\times \mathbb{S}^n\rightarrow \mathbb{S}\)</span>. <span class="math display">\[
\langle\mathbf{x}_a,\mathbf{x}_b\rangle_{F} = \bigoplus_{j=1}^n \mathbf{x}_a(j)\otimes\mathbf{x}_b(j)
\]</span></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp; Or, more generally, a semiring if inverse operations for <span class="math inline">\(\oplus,\otimes\)</span> don’t exist.</p></div></div><p>We can use this to perform “contractions” along any matching dimensions of matrices as well, since the sum index is well-defined. <span class="math display">\[
\begin{aligned}
X\in\mathbb{S}^{m\times n}\quad Y\in\mathbb{S}^{n\times m} \\
Z(i,j)=X\oplus,\otimes Y = \bigoplus_{j=1}^{n} X(i,j) \otimes Y(j,k) = XY
\end{aligned}
\]</span> For ease-of-use, we will assume the standard field for any given set <span class="math inline">\((\mathbb{S},+,\times)\)</span> if not specified otherwise, which recovers standard inner products <span class="math inline">\(\langle\cdot,\cdot\rangle\)</span>. However, <span class="citation" data-cites="MathematicalfoundationsGraphBLAS_Kepner2016"><a href="#ref-MathematicalfoundationsGraphBLAS_Kepner2016" role="doc-biblioref">[2]</a></span> illustrates the usefulness of various fields (or semirings). They allow linear-algebraic representation of many graph operations, such as shortest paths through inner products over <span class="math inline">\((\mathbb{R}\cup -\infty,\textrm{min}, +)\)</span>. This works because discrete/boolean edge weights will not accumulate extra strength beyond 1 under contraction over observations.</p>
<section id="kernels-distances" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="kernels-distances">Kernels &amp; distances</h3>
<p>As alluded to in the previous section, co-occurrence have a deep connection to a Gram matrix, which is a matrix of all pairwise inner products over a set of vectors.</p>
<p><span id="eq-gram-mat"><span class="math display">\[
X^TX=G(j,j')=\langle\mathbf{x'}_j,\mathbf{x}_{j'}'\rangle = \sum_{i=1}^{m} X(i,j)X(i,j')
\tag{2.4}\]</span></span></p>
<p>Matrices that can be decomposed into another matrix and its transpose are symmetric, and positive semidefinite (PSD), making every gram matrix PSD. They are directly related to (squared) euclidean distances through the polarization identity[CITE?]:<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <span id="eq-sq-distance"><span class="math display">\[
d^2(j,j') = \|\mathbf{x}_{j'}'-\mathbf{x}_{j'}'\|^2 = G(j,j) - 2G(j,j') + G(j',j')
\tag{2.5}\]</span></span></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;<strong>Important</strong>: these definitions are all using the <span class="math inline">\(\mathbf{x}'\)</span> notation to indicate that these measurements are almost exclusively being done in the <em>data space</em>, i.e.&nbsp;on column vectors. While most definitions work on distances in terms of the measurements/objects/data, for <em>inverse problems</em> (like network recovery, structure learning, etc.) they are more often applied in terms of the features (here, the nodes. This can be seen in statistics as well, where covariance and correlation matrices (which are related to the gram and distance matrix definitions above), are defined as relationships between features/dimensions, not individual samples.</p></div></div><p>In our example from before, the gram matrix will have entries showing the number of papers shared by two authors (or total papers by each, on the diagonal). This is because an inner product between two author (column) vectors will add 1 for each paper in the sum only if it has both authors in common. This is called a <em>bipartite projection</em>[CITE] into the authors “mode”, and is illustrated visually in <a href="../00-intro.html#fig-collab" class="quarto-xref">Figure&nbsp;<span>1.3 (a)</span></a>.</p>
<p>Due to [CITE Shoenberg/Mercer], we can generalize <a href="#eq-sq-distance" class="quarto-xref">Equation&nbsp;<span>2.5</span></a> such that <em>any</em> function “kernel” function <span class="math inline">\(\kappa(x,y)\)</span> that creates PSD matrix <span class="math inline">\(K(j,j')\in\mathbb{S}^{n\times n}\)</span>. It says that such a PSD matrix can always be decomposed into a form <span class="math inline">\(K=R^TR\)</span> for any matrix <span class="math inline">\(R(i,j)\in \mathbb{S}^{m\times n}\)</span>, thus letting us use the polarization identity to create arbitrary distance metrics. on <span class="math inline">\(\mathbb{S}^n\)</span> <span class="citation" data-cites="SimilaritiesgraphsKernels_Avrachenkov2019"><a href="#ref-SimilaritiesgraphsKernels_Avrachenkov2019" role="doc-biblioref">[4]</a></span><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> <span id="eq-dist-kernel"><span class="math display">\[
d_K(j,j') = \tfrac{1}{2}\left(K(j,j)+K(j',j'))\right)-K(j,j')
\tag{2.6}\]</span></span></p>
<div class="no-row-height column-margin column-container"><div id="ref-SimilaritiesgraphsKernels_Avrachenkov2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">K. Avrachenkov, P. Chebotarev, and D. Rubanov, <span>“Similarities on graphs: Kernels versus proximity measures,”</span> <em>European Journal of Combinatorics</em>, vol. 80, pp. 47–56, Aug. 2019, doi: <a href="https://doi.org/10.1016/j.ejc.2018.02.002">10.1016/j.ejc.2018.02.002</a>.</div>
</div><div id="fn10"><p><sup>10</sup>&nbsp; Distance metric, here, means that <span class="math inline">\(d(x,y)\)</span> satisfies the triangle inequality for all <span class="math inline">\(x,y\)</span>.</p></div></div><p>This ability to create valid distance measures from arbitrary kernel functions is the core of a vast area of machine learning and statistics that employs the so-called <em>kernel trick</em>. [CITE?] Different kernels yield different properties useful for distinguishing points having specific properties. One class of kernels are normalized to the range <span class="math inline">\([0,1]\)</span>, such that we ensure that equality along any one dimension is given a weight of <span class="math inline">\(\tilde{K}(j,j)=1\)</span>. Such a kernel matrix can be derived from any other kernel, and is often combined with a logarithmic similarity measure <span class="math inline">\(\tilde{\kappa}(x,y)=\log{s(x,y)}\)</span>. <span id="eq-norm-diag"><span class="math display">\[
\begin{aligned}
\tilde{K}(j,j') &amp;= \frac{K(j,j')}{\sqrt{K(j,j)^2K(j',j')^2}}\\
d_{\tilde{K}}(j,j') &amp;= -\log{\tilde{K}(j,j')}
\end{aligned}
\tag{2.7}\]</span></span> Since this is equivalent to applying <a href="#eq-dist-kernel" class="quarto-xref">Equation&nbsp;<span>2.6</span></a> to <span class="math inline">\(s\)</span> directly. This normalization should be familiar as the way cosine similarities and correlation matrices are made as well (also having 1s along their diagonal), and illustrates how non-metric similarities can be potentially made into (pseudo)metrics.</p>
</section>
<section id="incidence-structures-dependency" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="incidence-structures-dependency">Incidence structures &amp; dependency</h3>
<p>Rather than how “close” or “far” to points are in vector space, which is described with the kernels and distances above, whether something “touches”—or, is incident to—something else is usually described abstractly as an <em>incidence structure</em>. This is an abstract way to describe how things “touch”, such as when a set of points lie on a line/plane, or nodes touch an edge. We say an incidence structure is a triple of sets called (for historical reasons) <em>points</em> <span class="math inline">\(\mathfrak{P}\)</span>, <em>lines</em> <span class="math inline">\(\mathfrak{L}\)</span>, and <em>flags</em> <span class="math inline">\(\mathfrak{I}\)</span>.<span class="citation" data-cites="Incidencegeometry_Moorhouse2007"><a href="#ref-Incidencegeometry_Moorhouse2007" role="doc-biblioref">[5]</a></span> <span class="math display">\[(\mathfrak{P,L,I})\quad \mathfrak{I}\subseteq \mathfrak{P}\times\mathfrak{L}\]</span></p>
<div class="no-row-height column-margin column-container"><div id="ref-Incidencegeometry_Moorhouse2007" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">G. E. Moorhouse, <span>“Incidence geometry,”</span> <em>University of Wyoming</em>, pp. 3–5, 2007.</div>
</div></div><p>Representing these as matrices will be further explored in <a href="1-02-graph-obs.html#sec-incidence-vec" class="quarto-xref"><span>Graphs as incidence structures</span></a>. But, the discrete nature of these incidence sets makes it clear that estimating the size and elements of <span class="math inline">\(\mathfrak{I}\)</span>, is a very different question from estimating the similarity/distance between two entities in a vector space.</p>
<p>In statistics, such discrete structures usually arise when we are concerned with direct dependence from indirect. Take as an example a set of masses connected together by springs. If we shake one mass, all masses will also shake some amount, depending on the spring constants of the springs each mass is “transmitted” force through, and the losses due to friction or air resistance. While the amount of movement over time depends on how “close” in this spring network two masses are, the movement itself can only be transmitted through springs that the masses are <em>incident</em> to. Movement could be modeled through similarity/distance measurements like correlation, since none of the masses are independent (all move when any do), but incidence in terms of spring force transmission is modeled in terms of conditional (in)dependence. If we hold all but two masses still, and moving one doesn’t move the other, then we know they are conditionally independent: no spring connects them!</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/graphs.qmd" data-notebook-title="Source for figures" data-notebook-cellid="cell-fig-springs">
<div id="cell-fig-springs" class="cell" data-execution_count="24">
<div class="cell-output cell-output-display">
<div id="fig-springs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-springs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="1-01-matrix-meas_files/figure-html/..-codefigs-graphs-fig-springs-output-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-springs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: Spring system as a network of conditional dependencies
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>This idea gets formalized as probabilistic graphical models, which are networks that define “incidence” between two variables as conditional dependence. Letting the random variables in the column-space of <span class="math inline">\(X\)</span> be <span class="math inline">\(A,B\)</span> and the remaining columns be <span class="math inline">\(C=X(\cdot,J\setminus \{A,B\})\)</span>, then <span id="eq-cond-indep"><span class="math display">\[
P(A\cap B |C ) = P(A|C)P(B|C)\implies (A\perp B|C)\implies (A,B)\notin \mathfrak{I}
\tag{2.8}\]</span></span> for a set of incidences <span class="math inline">\(\mathfrak{I}\)</span> defining a PGM that was sampled as <span class="math inline">\(X\)</span>.</p>



</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../../content/00-intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../content/part1/1-02-graph-obs.html" class="pagination-link" aria-label="Vector representations of incidence">
        <span class="nav-page-text"><span class="chapter-title">Vector representations of incidence</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>