# Metrology as matrices



Where metrology is concerned, the actual unit of observation and how it is encoded for us is critical to how analysts may proceed with quantifying, modeling, and measuring uncertainty around observed phenomena. 
Experiment and observation tends to be organized as inputs and outputs, or, independent variables and dependent variables, specifically.
Independent variables are observed, multiple times ("observations"), and changes in outcome for each can be compared to the varying values associated with the independent variable input ("features").
For generality, say a practitioner records their measurements as scalar values, i.e. $x\in\mathbb{S}\in\{\mathbb{R,Z,N},\cdots\}$.
The structure most often used to record scalar values of $n$ independent/input variable features over the course of $m$ observations is called a design matrix $X:\mathbb{S}^{m\times n}$.^[
  Not all observations are scalar, but they can become so.
  If individual measurements are higher-dimensional (e.g. images are 2D), X is a tensor, which can be transformed through unrolling or embedding into a lower dimensional representation before proceeding. 
  There are other techniques for dealing with e.g. categorical data, such as one-hot encoding (where the features are binary for each possible category, with boolean entries for each observation).
]


## Observation and feature "spaces" {#sec-matrix-notation}

If we index a set of observations and features, respectively, as
$$ i\in I=\{1,\cdots,m\}, \quad j\in J=\{1,\cdots,n\},\qquad I,J:\mathbb{N}$$
then the design matrix can map the index of an observation and a feature to the corresponding measurement.
$$
x=X(i,j)\qquad X : I\times J \rightarrow \mathbb{S}
$$ {#eq-design-mat}
i.e. the measured value of the $j$th independent variable from the $i$th observation.^[
  This notation is adapted from the sparse linear algebraic treatment of graphs in @GraphAlgorithmsLanguage_Kepner2011 and @MathematicalfoundationsGraphBLAS_Kepner2016. 
]
In this scheme, an "observation" is a single row vector of features in $\mathbb{S}^{n\times 1}$ (or simply $\mathbb{S}^{n}$), such that each observation encodes a position in the space defined by the features, i.e. the _feature space_, and extracting a specific observation vector $i$ from the entire matrix can be denoted as
$$\mathbf{x}_i=X(i,\cdot),\quad \mathbf{x}:J\rightarrow\mathbb{S}$$
Similarly, every "feature" is associated with a single column vector in $\mathbb{S}^{1\times m}$, which can likewise be interpreted as a position in the space of observations (the _data space_):
$$\mathbf{x}_j^*=X(\cdot,j),\quad \mathbf{x}^*:I\rightarrow\mathbb{S}$$
Note that this definition could be swapped without loss of generality.
In other words, $\mathbf{x}$ and $\mathbf{x}^*$ being in row and column spaces is somewhat arbitrary, having more to do with the logistics of experiment design and data collection.
We could have measured our feature vectors one-at-a-time, measuring their values over an entire "population", in effect treating that as the independent variable set.^[
  In fact, vectors are often said to be in the column-space of a matrix, especially when using them as transformations in physics or deep learning layers.
  We generally follow a one-observation-per-row rule, unless otherwise stated.
]

To illustrate this formalism in a relevant domain, let's take another look at co-citation networks.
For $m$ papers we might be aware of $n$ total authors. 
For a given paper, we are able to see which authors are involved, and we say those authors "activated" for that paper.
It makes sense that our observations are individual papers, while the features might be the set of possible authors. 
However, we are not given information about which author was invited by which other one, or when each author signed on.
In other words, the measured values are strictly boolean, and we can structure our dataset as a design matrix $X:\mathbb{B}^{m\times n}$.
We can then think of the $i^{\mathrm{th}}$ paper as being represented by a vector $\mathbf{x}_i:\mathbb{B}^n$, and proceed using it in our various statistical models.
If we desired to analyze the set of authors, say, in order to determine their relative neighborhoods or latent author communities, we could equally use the feature vectors for each paper, this time represented in a vector $\mathbf{x}^*_j:\mathbb{B}^{1\times m}$.


## Models & linear operators {#sec-lin-ops}

Another powerful tool an analyst has is _modeling_ the observation process.
This is relevant when the observed data is hypothesized to be generated by a process we can represent mathematically, but we do not know the parameter values to best represent the observations (or the observations are "noisy" and we want to find a "best" parameters that account for this noise).
This is applicable to much of scientific inquiry, though one common use-case is the de-blurring of observed images (or de-noising of signals), since we might have a model for how blurring "operated" on the original image to give us the blurred one.
We call this "blurring" a _linear operator_ if it can be represented as a matrix^[in the finite-dimensional case], and applying it to a model with $l$ parameters is called the _forward map_:
$$\mathbf{x} = F\mathbf{p}\qquad F:\mathbb{R}^{l}\rightarrow \mathbb{R}^n$$
where $P$ is the space of possible parameter vectors, i.e. the _model space_.
The forward map takes a modeled vector and predicts a location in data space.

Of critical importance, then, is our ability to recover some model parameters from our observed data, e.g. if our images were blurred through convolution with a blurring kernel, then we are interested in _deconvolution_. 
If $F$ is invertible, the most direct solution might be to apply the operator to the data, as the _adjoint map_: 
$$ \mathbf{p} = F^H\mathbf{x}\qquad F^H:\mathbb{R}^{n}\rightarrow \mathbb{R}^l$$
which removes the effect of $F$ from the data $\mathbf{x}$ to recover the desired model $\mathbf{p}$.

Trivially we might have an orthogonal matrix $F$, so $F^H=F^{-1}$ is available directly.
In practice, other approaches are used to minimize the _residual_: $\hat{\mathbf{p}}^=\min_{\mathbf{p}} F\mathbf{p}-\mathbf{x}$.
Setting the gradient to 0 yields the normal equation, such that
$$ \hat{\mathbf{p}}=(F^TF)^{-1}F^T\mathbf{x}$$
This should be familiar to readers as equivalent to solving ordinary least-squares (OLS).
However, in that case it is more often shown as having the _design matrix_ $X$ in place of the operator $F$. 

_This is a critical distinction to make:_ OLS as a "supervised" learning method treats some of the observed data we represented as a design matrix previously as a target to be modeled, $y=X(\cdot,j)$, and the rest maps parameters into data space, $F=X(\cdot,J/j)$. 
With this paradigm, only the target is being "modeled" and the rest of the data is used to create the operator.
In the citation network example, it would be equivalent to trying to predict one variable, like citation count or a specific author's participation in every paper, _given_ every other author's participation in them.

For simplicity, most work in the supervised setting treats the reduced data matrix as X, opting to treat $y$ as a separate _dependent variable_.
However, our setting will remain _unsupervised_, since no single target variable is of specific interest---all observations are "data".
In this, we more closely align with the deconvolution literature, such that we are seeking a model and an operation on it that will produce the observed behavior in an "optimal" way. 




## Measurement quantification & error {#sec-smooth-err}

In binary data, such as what we have been considering, it is common to model observables as so-called "Bernoulli trials": events with two possible outcomes (on, off; yes, no; true, false), and one outcome has probability $p$. 
These can be thought of as weighted coin-flips: "heads" with probability $p$, and "tails" $1-p$.
If $k$ trials are performed (the "exposure"), we say the number of successes $s$ (the "count") is distributed as a binomial distribution $s\sim Bin(p,k)$.
The empirical estimate for the success probability is $\hat{p}=\tfrac{s}{k}$.

Note that this naturally resembles marginal sums on our design matrix $X$, if we treat columns (or rows!) as an array of samples from independent Bernoulli trials: $\hat{p}_j = \frac{\sum_{i\in I} X(i,j)}{m}$.
Many probability estimates involving repeated measurements of binary variables (not simply the row/column variables) have this sort of $\frac{\textrm{count}}{\textrm{exposure}}$ structure, as will become useful in later sections. 

However, if we are "measuring" a probability, we run into issues when we need to quantify our uncertainty about it.
For instance, an event might be quite rare, but if in our specific sample we _never_ see it, we still do not generally accept a probability of zero.


### Additive Smoothing

One approach to dealing with this involves adding _pseudocounts_ that smooth out our estimates for count/exposure, from which we get the name "additive smoothing".[CITE?]
$$\hat{p} = \frac{s+\alpha}{k+2\alpha} $$
Adding 1 success and 1 failure ($\alpha=1$) as pseudocounts to our observations is called _Laplace's Rule of Succession_, or simply "Laplace smoothing,"^[derived when Laplace desired estimates of probability for unobserved phenomena, such as the sun (not) rising tomorrow.] while adding $\alpha=0.5$ successes and failures is called using _Jeffrey's Prior_.
It's so-called because this pseudocount turns out to be a special case of selecting a Bayesian prior on the binomial probability (a.k.a. a _Beta-Binomial_ distribution) $p\sim \textrm{Beta}(\alpha, \beta)$, such that the posterior distribution after our success/failure counts is $\textrm{Beta}(s+\alpha, k-s+\beta)$, which has the mean
$$E[p|s,k]=\frac{s+\alpha}{k+\alpha+\beta}$$
which exactly recovers additive smoothing with a Jeffrey's prior for $\alpha=\beta=0.5$^[
  A useful comparison of the two priors (1, 0.5) is to ask, given all of the trials we have seen so far, whether we believe we are near the "end" of an average run of trials ($\alpha=1$, nearly all evidence has been collected), or about halfway through an average-length run ($\alpha=0.5$, only half of expected evidence has been observed).  
]
This generalization allows us to be more flexible, and specify our prior expectations on counts or exposure with more precision.
Such models provide both an estimate of the aleatory uncertainty (via the posterior distribution), and a form of "shrinkage" that prevents sampling noise from unduly affecting parameter estimates (via the prior distribution). 
Despite being a simple foundation, this treatment of "counts" and "exposure" can be built upon in many ways.

### Conditional Probabilities & Contingencies
 In dependency/structure recovery, since our goal involves estimating (at least) pairwise relationships, the independence assumption required to estimate node occurrences as Beta-Binomial is clearly violated^[
  In fact, a recent method from [@MultivariateBernoullidistribution_Dai2013] models probabilistic binary observations, _with dependencies_, by generalizing the mechanics overviewed here to a fully multivariate Bernoulli distribution, capable of including 3rd- and higher-order interractions, not just pairwise.  
].

However, it's natural to make use of joint ($P(A\cup B)$, how often does A happen with B, out of all data?) and conditional ($P(A|B)$ how often A given B; or $P(B|A)$, how often B given A) probabilities between nodes, while trying to estimate dependencies.
Once again, we can estimate the base probabilities for each node from marginal sums, but the joint and conditional probabilities can instead be estimated using matrix multiplication using the Gram matrix, discussed below.
It encodes pair-wise co-occurrence counts, such that $G(i,j):\mathbb{Z}^{n\times n}$ has the co-occurrence count for node "i" with "j".

The co-occurrence probability for each pair can be approximated with the beta-binomial scheme mentioned above, but care must be taken not to confuse this with the edge strength connecting two nodes.
First, nodes that rarely activate (low node probability) may nonetheless reliably connect to others when they do occur (high edge probability).
In fact, without direct observation of edges, we are not able to estimate their count, _or_ their exposure, which can be a source of systemic error from _epistemic uncertainty_.
We don't know when edges are used, directly, and we also don't have a reliable way to estimate the opportunities each edge had to activate (their exposure), either.
This is especially true when we wish to know whether an edge even _can_ be traversed, i.e. the edge _support_.
Support, as used in this sense, is the set of inputs for which we expect a non-zero output. 
Intuitively, this idea captures the sense that we might care more about _whether_ an edge/dependency exists, not _how important_ it is.
For that, we have to re-assess our simple model: even if we could count the number of times an edge might have been traversed, how do we estimate the opportunities it had to be available for traversal (it's "exposure")?


Assuming this kind of epistemic uncertainty can be adequately addressed through modeling---attempts at which will be discussed in more detail in @sec-lit-review---conditional probability/contingency tables will again be useful for validation.
When comparing estimated edge probability to some known "true" edge existence (if we have that), we can count the number of correct predictions, as well as type I (false positive) and type II (false negative) errors.
We can do this at _every probability/weight threshold value_, as well, and we will return to ways to aggregate all of these values into useful scoring metrics in @sec-FP-experiments. 


## Proximity vs. Incidence {#sec-products}

As alluded to in the previous section, co-occurrence seems to have a deep connection to a Gram matrix, which is a 

### Kernels & distances 

Importantly for the use of linear algebra, these values assigned for each feature are assumed to exist in a field (or, more generally, a semiring) $R$, equipped with operators analogous to addition ($\oplus$) and multiplication ($\otimes$) that allow for values to be aggregated through an inner product.
The matrix of all pairs of inner-products found by matrix multiplication (contracting over the feature space) is given by:

$$
G(\mathbf{x}_i, \mathbf{x}_j,R) = G_{ij} = \bigoplus_{k=1}^{n} x_{ik} \otimes x_{kj}
$$ {#eq-gen-matmul}

such that real-valued entries and a traditional "plus-times" inner product recovers the Gram matrix

$$
G_{ij}= X^TX\sum_{k=1}^{n} x_{ik}x_{kj}
$$

How "close" or "far away" things are.... Avrachenkov et al. 


Important: these measurements often assume distance is defined in terms of the measurements/objects/data, but for _inverse problems_, structure learning, etc., they are more often applied in terms of the features/operators.

Example with doc-term matrices 


The inner product between two papers will yield a "true" only if two papers share at least one author in common. 
This is called a _bipartite projection_[CITE], specifically the "papers" projection. 

Similarly, if our goal is to determine a network of "whether two authors ever coauthored", we could perform a bipartite projection using the boolean inner product in the observation space i.e. the "authors" projection.
It is this second projection, for determining a structure between features embedded into the  "observation" space, that we are primarily concerned with in this work, since it is the view that most closely resembles the concept of covariance or correlation between independent variables (features) in statistics more generally. 


### Incidence structures & dependency

foundational model of graph theory and incidence structures more broadly.
More to come, but get the terminology down.

::::{#fig-incidence-struct layout="[[1,1]]"}

::: {#fig-biadj-mat}
$$
%X(\{1,2,3,4,\cdots\})=\\
\begin{array}{c c}
& \begin{array}{cccccccccc} a & b & c & d & e & f & g & h & i & j\\ \end{array} \\
\begin{array}{c c } x_1\\x_2\\x_3\\x_4\\ \vdots \end{array} &
\left[
\begin{array}{c c c c c c c c c c}
  0  &  0  &  1  &  0  &  1  &  0  &  1  &  1  &  0  &  0 \\
  1  &  0  &  0  &  0  &  1  &  1  &  0  &  0  &  0  &  0 \\
  0  &  1  &  0  &  0  &  0  &  1  &  0  &  0  &  1  &  1 \\
  0  &  0  &  0  &  1  &  1  &  0  &  0  &  1  &  0  &  0 \\
  &&&& \vdots &&&&&
\end{array}
\right]
\end{array}
$$

:::

{{< embed ../codefigs/graphs.qmd#fig-bipartite >}}

::::



- Spring example, road example, etc.
- partial correlations



### Implications for networks
Usually dependencies are taken as causing or enabling proximity.
E.g. shortest paths, vs. edges.


- Discuss Complex Systems and their representation. 

The approach taken by researchers/investigators...do they assume a level of interchangeability between the two kinds of "relation"?
Do they define
Or do they 
