<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Recovery from Working Memory &amp; Partial Orders – Measuring Network Dependencies from Node Activations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../content/09-conclusion.html" rel="next">
<link href="../../content/part3/3-07-qualitative.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6d9f7168ccb3133a0c0fd8fac57d4f56.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
.flushright {
   text-align: right;
}
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/part3/3-07-qualitative.html">Applications &amp; Case Studies</a></li><li class="breadcrumb-item"><a href="../../content/part3/3-08-ordered.html"><span class="chapter-title">Recovery from Working Memory &amp; Partial Orders</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Measuring Network Dependencies from Node Activations</a> 
        <div class="sidebar-tools-main">
    <a href="../../Measuring-Network-Dependencies-from-Node-Activations.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreward</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/00-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">A Practitioner’s Guide to Network Recovery</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-01-matrix-meas.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Metrology with matrices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-02-graph-obs.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Vector representations of incidence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part1/1-03-recovery-road.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Roads to Network Recovery</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Nonparametric Network Recovery With Random Spanning Forests</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-04-rand-sf.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Latent Graphs with Desire Paths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-05-forest-pursuit.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Approximate Recovery in Near-linear Time by <em>Forest Pursuit</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part2/2-06-latent-forest-alloc.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Modifications &amp; Extensions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Applications &amp; Case Studies</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part3/3-07-qualitative.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Qualitative Application of Relationship Recovery</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/part3/3-08-ordered.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Recovery from Working Memory &amp; Partial Orders</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../content/09-conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Conclusion &amp; Future Work</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#technical-language-processing-with-invite" id="toc-technical-language-processing-with-invite" class="nav-link active" data-scroll-target="#technical-language-processing-with-invite">Technical Language Processing with INVITE</a>
  <ul class="collapse">
  <li><a href="#optimizing-absorbing-state-probabilities" id="toc-optimizing-absorbing-state-probabilities" class="nav-link" data-scroll-target="#optimizing-absorbing-state-probabilities">Optimizing absorbing-state probabilities</a></li>
  <li><a href="#application-mining-excavator-mwos" id="toc-application-mining-excavator-mwos" class="nav-link" data-scroll-target="#application-mining-excavator-mwos">Application: Mining Excavator MWOs</a></li>
  <li><a href="#which-network-assigns-tags-to-subsystems-most-like-a-domain-expert" id="toc-which-network-assigns-tags-to-subsystems-most-like-a-domain-expert" class="nav-link" data-scroll-target="#which-network-assigns-tags-to-subsystems-most-like-a-domain-expert">Which network assigns tags to subsystems most like a domain expert?</a></li>
  </ul></li>
  <li><a href="#sec-animal-fluency" id="toc-sec-animal-fluency" class="nav-link" data-scroll-target="#sec-animal-fluency">Forest Pursuit Animal Network</a>
  <ul class="collapse">
  <li><a href="#domain-aware-preprocessing" id="toc-domain-aware-preprocessing" class="nav-link" data-scroll-target="#domain-aware-preprocessing">Domain-aware preprocessing</a></li>
  <li><a href="#sec-edge-diversity" id="toc-sec-edge-diversity" class="nav-link" data-scroll-target="#sec-edge-diversity">Edge Connective Efficiency and Diversity</a></li>
  <li><a href="#thresholded-structure-preservation" id="toc-thresholded-structure-preservation" class="nav-link" data-scroll-target="#thresholded-structure-preservation">Thresholded Structure Preservation</a></li>
  <li><a href="#sec-fp-preprocess" id="toc-sec-fp-preprocess" class="nav-link" data-scroll-target="#sec-fp-preprocess">Forest Pursuit as Preprocessing</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../content/part3/3-07-qualitative.html">Applications &amp; Case Studies</a></li><li class="breadcrumb-item"><a href="../../content/part3/3-08-ordered.html"><span class="chapter-title">Recovery from Working Memory &amp; Partial Orders</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ordered" class="quarto-section-identifier"><span class="chapter-title">Recovery from Working Memory &amp; Partial Orders</span></span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<div class="flushright">
<div class="minipage">
<blockquote class="blockquote">
<p><em>“So an analytically astute observer would find that a salmon is more closely related to a camel than it is to a hagfish. On what basis, then, do we justify grouping salmon under the label fish, but not camels?”</em></p>
<p>– Samuel Beswick (sarcastically)<br>
</p>
</blockquote>
</div>
</div>
<p>This whole time we have assumed that the ordering of nodes was unknown, or at the very least unreliable. However, there are frequently cases, especially in text processing applications, where we have some sense of an ordering on activations. By <em>partial order</em> on a set (a “poset”), we mean that all elements are either comparable as greater (before) or less (after), or incomparable. The set of posets is therefore precisely isomorphic to the set of <em>directed acyclic graphs</em>, based on reachability.</p>
<p>Our original example with authors might be thought of as a poset: (i) precedes/asks (f) and (j), (j) precedes/asks (b), but (b) and (f) are incomparable. We don’t know if (i) asked (f) before or after (j) asked (b).<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> We have updated the original example with explicit partial orders in <a href="#fig-obs-tree" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>. Note that nodes in some lists could be re-arranged while keeping the partial order the same (keeping all arrows pointing to the right).</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp; Interestingly, in the case where the node activations <em>are</em> given a total order (in the form of <em>timestamps</em>), <span class="citation" data-cites="Inferringnetworksdiffusion_GomezRodriguez2012"><a href="#ref-Inferringnetworksdiffusion_GomezRodriguez2012" role="doc-biblioref">[1]</a></span> derive an algorithm called <em>NetInf</em>. It utilizes sums over minimum spanning trees that satisfy time constraints, similar to a special case of Forest Pursuit where all activations have a total ordering.</p><div id="ref-Inferringnetworksdiffusion_GomezRodriguez2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">M. Gomez-Rodriguez, J. Leskovec, and A. Krause, <span>“Inferring networks of diffusion and influence,”</span> <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>, vol. 5, no. 4, pp. 1–37, 2012, doi: <a href="https://doi.org/10.1145/2086737.2086741">10.1145/2086737.2086741</a>.</div>
</div></div></div><div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/graphs.qmd" data-notebook-title="Source for figures" data-notebook-cellid="cell-fig-obs-tree">
<div id="cell-fig-obs-tree" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<div id="fig-obs-tree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-obs-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-graphs-fig-obs-tree-output-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-obs-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: Observations as partially-ordered sets
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Sadly our co-authorship example does not often include the (partial) order of author additions,<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> but other common network recovery problems do have an inherent order to them. A very common need is to recover concept association networks, whether from lists of tags or directly from a corpus of written language. What’s needed is an assumption on how the observed partial order of concepts is generated. <span class="citation" data-cites="ForagingSemanticFields_Hills2015"><a href="#ref-ForagingSemanticFields_Hills2015" role="doc-biblioref">[2]</a></span> proposes a “foraging” mechanism, so that concepts get sequentially recalled from “semantic patches” of nearby concepts in memory. The partial order comes from our ability to maintain more than one concept in working memory, so that the next concept can be “foraged” from any of the other recently recalled ones<span class="citation" data-cites="magicalnumberseven_Miller1956 Dynamicsearchworking_Hills2012"><a href="#ref-magicalnumberseven_Miller1956" role="doc-biblioref">[3]</a>, <a href="#ref-Dynamicsearchworking_Hills2012" role="doc-biblioref">[4]</a></span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;though some domains do imbue special meaning to the listed author order, a fact that might be interesting to investigate in future network recovery efforts!</p></div><div id="ref-ForagingSemanticFields_Hills2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">T. T. Hills, P. M. Todd, and M. N. Jones, <span>“Foraging in semantic fields: How we search through memory,”</span> <em>Topics in Cognitive Science</em>, vol. 7, no. 3, pp. 513–534, Jun. 2015, doi: <a href="https://doi.org/10.1111/tops.12151">10.1111/tops.12151</a>.</div>
</div><div id="ref-Dynamicsearchworking_Hills2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">T. T. Hills and T. Pachur, <span>“Dynamic search and working memory in social recall.”</span> <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, vol. 38, no. 1, pp. 218–228, 2012, doi: <a href="https://doi.org/10.1037/a0025161">10.1037/a0025161</a>.</div>
</div><div id="ref-Technicallanguageprocessing_Brundage2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">M. P. Brundage, R. Sexton, M. Hodkiewicz, A. Dima, and S. Lukens, <span>“Technical language processing: Unlocking maintenance knowledge,”</span> <em>Manufacturing Letters</em>, vol. 27, pp. 42–46, Jan. 2021, doi: <a href="https://doi.org/10.1016/j.mfglet.2020.11.001">10.1016/j.mfglet.2020.11.001</a>.</div>
</div><div id="ref-UsingSemanticFluency_Sexton2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">R. Sexton and M. Fuge, <span>“Using semantic fluency models improves network reconstruction accuracy of tacit engineering knowledge,”</span> in <em>Volume 2A: 45th design automation conference</em>, American Society of Mechanical Engineers, Aug. 2019. doi: <a href="https://doi.org/10.1115/detc2019-98429">10.1115/detc2019-98429</a>.</div>
</div><div id="ref-OrganizingTaggedKnowledge_Sexton2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">R. Sexton and M. Fuge, <span>“Organizing tagged knowledge: Similarity measures and semantic fluency in structure mining,”</span> <em>Journal of Mechanical Design</em>, vol. 142, no. 3, Jan. 2020, doi: <a href="https://doi.org/10.1115/1.4045686">10.1115/1.4045686</a>.</div>
</div></div><p>In this section, we briefly cover a method for network inference by <span class="citation" data-cites="Humanmemorysearch_Jun2015"><a href="#ref-Humanmemorysearch_Jun2015" role="doc-biblioref">[5]</a></span> that utilizes partial order information from ordered lists of concepts, called INVITE. We use it to demonstrate improvement over bag-of-words and markov assumptions for downstream technical language processing <span class="citation" data-cites="Technicallanguageprocessing_Brundage2021"><a href="#ref-Technicallanguageprocessing_Brundage2021" role="doc-biblioref">[6]</a></span> tasks, as originally demonstrated in <span class="citation" data-cites="UsingSemanticFluency_Sexton2019 OrganizingTaggedKnowledge_Sexton2020"><a href="#ref-UsingSemanticFluency_Sexton2019" role="doc-biblioref">[7]</a>, and <a href="#ref-OrganizingTaggedKnowledge_Sexton2020" role="doc-biblioref">[8]</a></span></p>
<p>Finally, we show that using <em>Forest Pursuit</em> for partially ordered data can still be quite useful for network backboning, and for a fraction of the computational cost. We investigate a network recovery task from verbal/semantic fluency data <span class="citation" data-cites="Estimatingsemanticnetworks_Zemla2018"><a href="#ref-Estimatingsemanticnetworks_Zemla2018" role="doc-biblioref">[9]</a></span>, which involves recovery of a network of animal relationships from memory and recall experiments. Even without directly using partial order information, proper data preparation along with previously-discussed (un-ordered) recovery methods can lead to significantly improved network backboning and analysis capability</p>
<div class="no-row-height column-margin column-container"></div><section id="technical-language-processing-with-invite" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="technical-language-processing-with-invite">Technical Language Processing with INVITE</h2>
<p>Maintenance work orders are often represented as categorized data, though increasingly quantitative use of a technician’s descriptions is being pursued by maintenance management operations <span class="citation" data-cites="BenchmarkingKeywordExtraction_Sexton2018 CategorizationErrorsData_Sexton2019"><a href="#ref-BenchmarkingKeywordExtraction_Sexton2018" role="doc-biblioref">[10]</a>, <a href="#ref-CategorizationErrorsData_Sexton2019" role="doc-biblioref">[11]</a></span>. Tags are another way to flexibly structure this otherwise “unstructured” data, which <a href="#tbl-mwo" class="quarto-xref">Table&nbsp;<span>9.1</span></a> shows in comparison to more traditional categorization.</p>
<div class="no-row-height column-margin column-container"><div id="ref-CategorizationErrorsData_Sexton2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">R. Sexton, M. Hodkiewicz, and M. P. Brundage, <span>“Categorization errors for data entry in maintenance work-orders,”</span> <em>Annual Conference of the <span>PHM</span> Society</em>, vol. 11, no. 1, Sep. 2019, doi: <a href="https://doi.org/10.36001/phmconf.2019.v11i1.790">10.36001/phmconf.2019.v11i1.790</a>.</div>
</div></div><div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/graphs.qmd" data-notebook-title="Source for figures" data-notebook-cellid="cell-tbl-mwo">
<div class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="27">
<div id="tbl-mwo" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="27">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mwo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.1: Maintenance Work Order as categorized vs.&nbsp;tagged data
</figcaption>
<div aria-describedby="tbl-mwo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="tbl-mwo-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-mwo-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
<div aria-describedby="tbl-mwo-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-graphs-tbl-mwo-output-1.svg" id="tbl-mwo-1" class="img-fluid figure-img" data-ref-parent="tbl-mwo">
</div>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
</div>
<p>Whether entered directly or generated from text by keyword extraction, the tags will tend to have ordering information readily available. A traditional way to model this kind of text is through either bag-of-words (the co-occurrence node activation data already discussed) or as a sequence of order-n markov model emissions. An order-n markov model <span class="math inline">\(\text{MC}n\)</span> estimates the probability of observing the <span class="math inline">\(i\)</span>th item <span class="math inline">\(t_i\)</span> in a sequence <span class="math inline">\(T\)</span> as <span class="math display">\[
P(t_i|T) \approx P(t_i | t_{i-1}, \cdots,t_{i-n})
\]</span></p>
<p>Unlike the clique bias from before, assuming markov jumps for each observation leads to a different kind of bias, with higher precision but reduced recall as shown in <a href="#fig-stack-markov" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/graphs.qmd" data-notebook-title="Source for figures" data-notebook-cellid="cell-fig-stack-markov">
<div id="cell-fig-stack-markov" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="26">
<div class="cell-output cell-output-display">
<div id="fig-stack-markov" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stack-markov-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-graphs-fig-stack-markov-output-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stack-markov-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.2: Partial-order edge measurements with Markov assumption
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Without knowing the underlying dependency relationships, it’s difficult to estimate which edges were used by a random-walker, since subsequent visits in memory to a “tag” are not being reported once a technician first adds it. <span class="citation" data-cites="Humanmemorysearch_Jun2015"><a href="#ref-Humanmemorysearch_Jun2015" role="doc-biblioref">[5]</a></span> call this an “Initial-visit-emitting” random walk, or INVITE for short. To more accurately recover the network, they suggest maximizing the absorption probability for each step of a partial order, individually, knowing which nodes have already been activated.</p>
<div class="no-row-height column-margin column-container"></div><section id="optimizing-absorbing-state-probabilities" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="optimizing-absorbing-state-probabilities">Optimizing absorbing-state probabilities</h3>
<p>Say the set of components or concepts that have a corresponding tag in our system is denoted by the node-set <span class="math inline">\(N\)</span>. A user-given set of <span class="math inline">\(T\)</span>&nbsp;<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> for a specific record can be denoted as a Random Walk (RW) trajectory <span class="math inline">\(\mathbf{t}=\{t_1, t_2, t_3, \cdots t_{T}\}\)</span>, where <span class="math inline">\(T\leq N\)</span>. This limit on the size of <span class="math inline">\(T\)</span> assumes tags are a set of unique entries. Any transitions between previously visited tags in <span class="math inline">\(\mathbf{t}\)</span> will not be directly observed, making the transitions observed in <span class="math inline">\(\mathbf{t}\)</span> strictly non-Markov, and allowing for a <em>potentially infinite</em> number of possible paths to arrive at the next tag <em>through previously visited ones</em>. Instead of directly computing over this intractable model for generating <span class="math inline">\(\mathbf{t}\)</span>, the key insight from the original INVITE paper&nbsp;<span class="citation" data-cites="Humanmemorysearch_Jun2015"><a href="#ref-Humanmemorysearch_Jun2015" role="doc-biblioref">[5]</a></span> comes from partitioning <span class="math inline">\(\mathbf{t}\)</span> into <span class="math inline">\(T-1\)</span> Markov chains with absorbing states. Previously visited tags are “transient” states, and unseen tags are “absorbing”. It is then possible to calculate the absorption probability into the <span class="math inline">\(k\)</span> transition (<span class="math inline">\(t_k \rightarrow t_{k+1}\)</span>) using the <em>fundamental matrix</em> of each partition. If the partitions at this jump consist of <span class="math inline">\(q\)</span> transient states with transition matrix among themselves <span class="math inline">\(\mathbf{Q}^{(k)}_{q\times q}\)</span>, and <span class="math inline">\(r\)</span> absorbing states with transitions into them from <span class="math inline">\(q\)</span> as <span class="math inline">\(\mathbf{R}^{(k)}_{q\times r}\)</span>, the Markov transition matrix <span class="math inline">\(\mathbf{M}^{(k)}_{n\times n}\)</span> has the form <span id="eq-trans-matrix"><span class="math display">\[
\mathbf{M}^{(k)} =
    \begin{pmatrix}
        \mathbf{Q}^{(k)}  &amp; \mathbf{R}^{(k)} \\
        \mathbf{0}        &amp; \mathbf{I}
    \end{pmatrix}
\tag{9.1}\]</span></span></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;While some sources use “tagging” as a proxy for a set of strictly un-ordered labels (as in multi-label classification), we preserve the mechanism by which the tags were generated in the first place, i.e., in a <em>specific</em> order.</p></div><div id="ref-Humanmemorysearch_Jun2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">K.-S. Jun, J. Zhu, T. T. Rogers, Z. Yang, <em>et al.</em>, <span>“Human memory search as initial-visit emitting random walk,”</span> <em>Advances in neural information processing systems</em>, vol. 28, no. 20, pp. 2389–2393, 2015, doi: <a href="https://doi.org/10.1016/j.physleta.2019.04.060">10.1016/j.physleta.2019.04.060</a>.</div>
</div><div id="ref-RandomWalksElectric_Doyle2000" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">P. G. Doyle and J. L. Snell, <span>“Random walks and electric networks.”</span> arXiv, 2000. doi: <a href="https://doi.org/10.48550/ARXIV.MATH/0001057">10.48550/ARXIV.MATH/0001057</a>.</div>
</div></div><p>Here <span class="math inline">\(\mathbf{0}\)</span>, <span class="math inline">\(\mathbf{I}\)</span> represent lack of transition between/from absorbing states. It follows from <span class="citation" data-cites="RandomWalksElectric_Doyle2000"><a href="#ref-RandomWalksElectric_Doyle2000" role="doc-biblioref">[12]</a></span> that the probability <span class="math inline">\(P\)</span> of a chain starting at <span class="math inline">\(t_k\)</span> being absorbed into state <span class="math inline">\(k+1\)</span>, is given as <span id="eq-absorb"><span class="math display">\[
\begin{gathered}
    P\left(t_{k+1} \middle| t_{1:k},\mathbf{M}\right) =
        \left.\mathbf{N}^{(k)}R^{(k)}\right|_{q,1}\\
\mathbf{N} = \left( \mathbf{I}-\mathbf{Q} \right) ^{-1}
\end{gathered}
\tag{9.2}\]</span></span></p>
<p>The probability of being absorbed at <span class="math inline">\(k+1\)</span> conditioned on jumps <span class="math inline">\(1:k\)</span> is thus equivalent to the probability of observing the <span class="math inline">\(k+1\)</span> INVITE tag. If we approximate an a priori distribution of tag probabilities to initialize our chain as <span class="math inline">\(t_1\sim\text{Cat}(n,\theta)\)</span> (which could be empirically derived or simulated), then the likelihood of our observed tag chain <span class="math inline">\(\mathbf{t}\)</span>, given a transition matrix, is: <span class="math display">\[
\mathcal{L}\left(\mathbf{t}| \theta, \mathbf{M}\right) =
        \theta(t_1)\prod_{k=1}^{T-1} P\left(t_{k+1}\,\middle|\ t_{1:k},\mathbf{M}\right)
\]</span></p>
<p>Finally, if we observe a set of tag lists <span class="math inline">\(\mathbf{C} = \left\{ \mathbf{t}_1, \mathbf{t}_2, \cdots, \mathbf{t}_{c} \right\}\)</span>, and assume <span class="math inline">\(\theta\)</span> can be estimated independently of <span class="math inline">\(\mathbf{M}\)</span>, then we can frame the problem of structure mining on observed INVITE data as a minimization of negative log-likelihood. A point estimate for our association network given <span class="math inline">\(\mathbf{M}\)</span> can found as: <span class="math display">\[
    \mathbf{M}^* \leftarrow \operatorname*{argmin}_{\mathbf{M}} \quad
    \sum_{i=1}^{C}
    \sum_{k=1}^{T_i-1}
        -\log \mathcal{L} \left(t^{(i)}_{k+1} \middle| t^{(i)}_{1:k},\mathbf{M}\right)
\]</span></p>
<p>This (deeply nested) likelihood can now be optimized using standard solvers, and our reference implementation uses stochastic gradient descent via PyTorch <span class="citation" data-cites="AutomaticdifferentiationPyTorch_Paszke2017"><a href="#ref-AutomaticdifferentiationPyTorch_Paszke2017" role="doc-biblioref">[13]</a></span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="ref-AutomaticdifferentiationPyTorch_Paszke2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">A. Paszke <em>et al.</em>, <span>“Automatic differentiation in PyTorch,”</span> in <em>NIPS-w</em>, 2017.</div>
</div><div id="fn4"><p><sup>4</sup>&nbsp; The n-gram markov transition models (MC1,MC2) trained for comparison vs INVITE were trained using <code>pomegranate</code><span class="citation" data-cites="Pomegranatefastflexible_Schreiber2018"><a href="#ref-Pomegranatefastflexible_Schreiber2018" role="doc-biblioref">[14]</a></span>.</p><div id="ref-Pomegranatefastflexible_Schreiber2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">J. Schreiber, <span>“Pomegranate: Fast and flexible probabilistic modeling in python,”</span> <em>Journal of Machine Learning Research</em>, vol. 18, no. 164, pp. 1–6, 2018.</div>
</div></div></div></section>
<section id="application-mining-excavator-mwos" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="application-mining-excavator-mwos">Application: Mining Excavator MWOs</h3>
<p>To assess the applicability of the INVITE-based similarity measure to real-world scenarios, we apply our model to tags annotated for a mining dataset pertaining to 8 similarly-sized excavators at various sites across Australia&nbsp;<span class="citation" data-cites="Whyautonomousassets_Hodkiewicz2017 Cleaninghistoricalmaintenance_Hodkiewicz2016"><a href="#ref-Whyautonomousassets_Hodkiewicz2017" role="doc-biblioref">[15]</a>, <a href="#ref-Cleaninghistoricalmaintenance_Hodkiewicz2016" role="doc-biblioref">[16]</a></span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Whyautonomousassets_Hodkiewicz2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">M. R. Hodkiewicz, Z. Batsioudis, T. Radomiljac, and M. T. Ho, <span>“Why autonomous assets are good for reliability–the impact of ‘operator-related component’failures on heavy mobile equipment reliability,”</span> in <em>Annual conference of the prognostics and health management society 2017</em>, 2017.</div>
</div><div id="ref-Cleaninghistoricalmaintenance_Hodkiewicz2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">M. Hodkiewicz and M. T.-W. Ho, <span>“Cleaning historical maintenance work order data for reliability analysis,”</span> <em>Journal of Quality in Maintenance Engineering</em>, vol. 22, no. 2, pp. 146–163, 2016.</div>
</div><div id="ref-NestorToolNatural_Sexton2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">R. B. Sexton and M. B. Brundage, <span>“Nestor: A tool for natural language annotation of short texts,”</span> <em>Journal of Research of the National Institute of Standards and Technology</em>, vol. 124, Nov. 2019, doi: <a href="https://doi.org/10.6028/jres.124.029">10.6028/jres.124.029</a>.</div>
</div><div id="ref-BenchmarkingKeywordExtraction_Sexton2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">R. Sexton, M. Hodkiewicz, M. P. Brundage, and T. Smoker, <span>“Benchmarking for keyword extraction methodologies in maintenance work orders,”</span> <em>Annual Conference of the <span>PHM</span> Society</em>, vol. 10, no. 1, Sep. 2018, doi: <a href="https://doi.org/10.36001/phmconf.2018.v10i1.541">10.36001/phmconf.2018.v10i1.541</a>.</div>
</div></div><p>The tags were created by a subject-matter expert spending 1 hour of time in the annotation assistance tool <code>nestor</code>&nbsp;<span class="citation" data-cites="NestorToolNatural_Sexton2019"><a href="#ref-NestorToolNatural_Sexton2019" role="doc-biblioref">[17]</a></span>, using a methodology outlined in a previous benchmarking study for that annotation method&nbsp;<span class="citation" data-cites="BenchmarkingKeywordExtraction_Sexton2018"><a href="#ref-BenchmarkingKeywordExtraction_Sexton2018" role="doc-biblioref">[10]</a></span>.</p>
<p>That work compared the ability of tags to estimate survival curves and mean time-to-failure, when compared with a custom-designed keyword extraction tool based on classifying the maintenance issues by subsystem. While certain sets of tags were able to predict time-to-failure with high accuracy for certain subsystems, a key problem identified in that work is knowing a priori which tags best indicate when a subsystem is failing?</p>
<blockquote class="blockquote">
<p><em>Which tags best represent a given subsystem?</em></p>
</blockquote>
<p>Some tags are sufficient (albeit unnecessary) conditions to indicate a subsystem. That the “hydraulic” tag indicates a <em>Hydraulic System</em> MWO is obvious, but so might a “valve” tag—“hydraulic” is implied but not present. Consequently, we can treat the problem of assigning tags to represent a subsystem as a semi-supervised multi-class classification problem in the style of <span class="citation" data-cites="Semisupervisedlearning_Avrachenkov2017"><a href="#ref-Semisupervisedlearning_Avrachenkov2017" role="doc-biblioref">[18]</a></span>. Like in that work, we need to know a selection tag<span class="math inline">\(\rightarrow\)</span>subsystem assignments, as well as network of weighted tag-tag edges.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Semisupervisedlearning_Avrachenkov2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">K. Avrachenkov, P. Chebotarev, and A. Mishenin, <span>“Semi-supervised learning with regularized laplacian,”</span> <em>Optimization Methods and Software</em>, vol. 32, no. 2, pp. 222–236, Mar. 2017, doi: <a href="https://doi.org/10.1080/10556788.2016.1193176">10.1080/10556788.2016.1193176</a>.</div>
</div><div id="ref-sharedreliabilitydatabase_Ho2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">M. Ho, <span>“A shared reliability database for mobile mining equipment,”</span> PhD thesis, University of Western Australia, 2015.</div>
</div></div><p>Then, if we can compare the semi-supervised tag classifications to a ground-truth classification by a human annotator (which are available for the excavator dataset thanks to <span class="citation" data-cites="sharedreliabilitydatabase_Ho2015"><a href="#ref-sharedreliabilitydatabase_Ho2015" role="doc-biblioref">[19]</a></span>), we can assess the ability of each network to capture the human annotator’s internal/cognitive tag relationship structure.</p>
</section>
<section id="which-network-assigns-tags-to-subsystems-most-like-a-domain-expert" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="which-network-assigns-tags-to-subsystems-most-like-a-domain-expert">Which network assigns tags to subsystems most like a domain expert?</h3>
<p>To test the ability of the similarity measures to accomplish this, the top three most common subsystems in the data were used as classes, namely, Hydraulic System, Engine, and Bucket. The tags “hydraulic”, “engine”, and “bucket” were assigned to those subsystems as known labels, respectively. Tags were filtered to only include ones of high-importance and sufficient information: only work orders containing at least 3 unique tags, and only tags that occurred at least 10 unique times within the those work orders, were included for this analysis (<span class="math inline">\(C=263\)</span> MWOs, <span class="math inline">\(N=40\)</span> tags). Then the number of occurrences for every tag can be compared across subsystems, giving each tag a ground-truth multinomial (categorical) probability distribution for occurring within each subsystem. We determine ground-truth classification labels as subsystems that account for <span class="math inline">\(\geq60\%\)</span> of each tag’s occurrences. Tags more balanced than that are considered “unknown subsystem”.</p>
<p>To perform semi-supervised classification on the recovered relationship graphs, we use a label-spreading algorithm described in&nbsp;<span class="citation" data-cites="Learninglocalglobal_Zhou2004"><a href="#ref-Learninglocalglobal_Zhou2004" role="doc-biblioref">[20]</a></span>, which itself was inspired by spreading activation networks in experimental psychology&nbsp;<span class="citation" data-cites="architecturecognition_Anderson2013 Observationphasetransitions_Shrager1987"><a href="#ref-architecturecognition_Anderson2013" role="doc-biblioref">[21]</a>, <a href="#ref-Observationphasetransitions_Shrager1987" role="doc-biblioref">[22]</a></span>. The result of this algorithm is tags having a score for each class, with the classification being the maximally scored class for that tag. These class assignments can then be compared to the ground-truth labels, which we have done by weighted macro-averaging of the <span class="math inline">\(F_1\)</span>-score (see <a href="#fig-excavate-f1kl" class="quarto-xref">Figure&nbsp;<span>9.3 (a)</span></a>).</p>
<div class="no-row-height column-margin column-container"><div id="ref-Learninglocalglobal_Zhou2004" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Schölkopf, <span>“Learning with local and global consistency,”</span> in <em>Advances in neural information processing systems</em>, 2004, pp. 321–328.</div>
</div><div id="ref-architecturecognition_Anderson2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">J. R. Anderson, <em>The architecture of cognition</em>. Psychology Press, 2013.</div>
</div><div id="ref-Observationphasetransitions_Shrager1987" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">J. Shrager, T. Hogg, and B. A. Huberman, <span>“Observation of phase transitions in spreading activation networks,”</span> <em>Science</em>, vol. 236, no. 4805, pp. 1092–1094, 1987.</div>
</div></div><div id="fig-excavate-results" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-excavate-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="fig-excavate-f1kl" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-excavate-f1kl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../images/F1_KL_ntags3_freq5_topn50_thres60_saveTrue.svg" id="fig-excavate-f1kl" class="img-fluid figure-img" data-ref-parent="fig-excavate-results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-excavate-f1kl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
<div id="fig-excavate-ternary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-excavate-ternary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../images/ternary_ntags3_freq5_topn50_thres60_saveTrue.svg" id="fig-excavate-ternary" class="img-fluid figure-img" data-ref-parent="fig-excavate-results">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-excavate-ternary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-excavate-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.3: Semisupervised MWO Tag Classification with Network Label Propagation
</figcaption>
</figure>
</div>
<p>The classification of the INVITE-based similarity measure far outperforms the other measures as a preprocessor for label-spreading, when measured by average <span class="math inline">\(F_1\)</span>-score. However, since these “classifications” are actually thresholded multinomial distributions (with some tags regularly occurring across multiple subsystems), how do we know if an underlying structure has actually been recovered, rather than simply a black-box classifier that happens to perform well at this setting?</p>
<p>To begin answering this question, we might ask whether the relative scores returned by label-spreading are similar to the original multinomial distributions themselves, rather than the overall classification. To find out, we use softmax normalization<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> to transform each tag’s scores into a “predicted multinomial”, before finally calculating the Kullback-Leibler divergence (KLD) between the true and predicted multinomials for every tag. The total KLD, summed over all tags, is also shown in <a href="#fig-excavate-ternary" class="quarto-xref">Figure&nbsp;<span>9.3 (b)</span></a>, along with positions of each tag’s multinomial as projected onto the 2-simplex for the true and <span class="math inline">\(F_1\)</span>-optimal predicted distributions. Once again, the INVITE performs much better at this task, over a wide range of <span class="math inline">\(\sigma\)</span> (lower is better).</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;For visualization, a temperature parameter was added to softmax, and this was optimized for minimum KLD via Brent’s method&nbsp;<span class="citation" data-cites="algorithmguaranteedconvergence_Brent1971"><a href="#ref-algorithmguaranteedconvergence_Brent1971" role="doc-biblioref">[23]</a></span> for each similarity measure independently to provide an equal footing for comparison.</p><div id="ref-algorithmguaranteedconvergence_Brent1971" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">R. P. Brent, <span>“An algorithm with guaranteed convergence for finding a zero of a function,”</span> <em>The Computer Journal</em>, vol. 14, no. 4, pp. 422–425, 1971.</div>
</div></div></div><p>A reason for the performance disparity can be seen in the simplex projections: recovered topology via INVITE-similarity does a much better job of separating the three classes, while not letting any single tag overcompensate by dominating a subsystem’s area. Even the “unknown” tags are correctly placed roughly between Bucket and Hydraulic System regions, reflecting the true topology of the system.</p>
</section>
</section>
<section id="sec-animal-fluency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-animal-fluency">Forest Pursuit Animal Network</h2>
<p>For our last case study, we return to Forest Pursuit as a useful tool for analysis even when that might mean ignoring partial ordering information. Note that <a href="#eq-absorb" class="quarto-xref">Equation&nbsp;<span>9.2</span></a> is effectively the same as a (<span class="math inline">\(\beta=1\)</span>) forest matrix if the transition (normalized adjacency) matrix was replaced by a (sub-)graph laplacian. Intuitively, the INVITE loss function is summing up over absorption (log-)probabilities at each new node activation: i.e.&nbsp;each step of a tree’s creation. Because the probability of a sampled tree is precisely proportional to the product of its edge weights, then weighing a tree by its absorption probabilities and running INVITE should have a mathematically similar effect as the FP estimate. The similarity would be exact whenever the tree that set of nodes traveled along <em>was</em> the mode of the tree distribution: the MST.</p>
<p>In other words, whenever the random walks <em>did</em> use the minimum distance to reach each node, the two methods should be equivalent. While this isn’t happening much individually, the effect of <em>many</em> random walks will average out to this MST, precisely because <em>it is the tree distribution mode</em> from which we assume node activations sample under <em>marked Random Spanning Forests</em>.</p>
<p>To illustrate FP’s efficacy in network estimation despite ignoring partial order information, we turn to a classic network recovery problem in this space: <em>semantic networks from fluency data</em><span class="citation" data-cites="newdissimilaritymeasure_Prescott2006 Estimatingsemanticnetworks_Zemla2018 semanticorganizationanimal_Goni2011"><a href="#ref-Estimatingsemanticnetworks_Zemla2018" role="doc-biblioref">[9]</a>, <a href="#ref-newdissimilaritymeasure_Prescott2006" role="doc-biblioref">[24]</a>, <a href="#ref-semanticorganizationanimal_Goni2011" role="doc-biblioref">[25]</a></span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-newdissimilaritymeasure_Prescott2006" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">T. J. Prescott, L. D. Newton, N. U. Mir, P. W. R. Woodruff, and R. W. Parks, <span>“A new dissimilarity measure for finding semantic structure in category fluency data with implications for understanding memory organization in schizophrenia.”</span> <em>Neuropsychology</em>, vol. 20, no. 6, pp. 685–699, Nov. 2006, doi: <a href="https://doi.org/10.1037/0894-4105.20.6.685">10.1037/0894-4105.20.6.685</a>.</div>
</div></div><section id="domain-aware-preprocessing" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="domain-aware-preprocessing">Domain-aware preprocessing</h3>
<p>Verbal (semantic) fluency tests involve asking participants to list as many items belonging to a prompted category in their available time. For instance, an “animals” prompt could lead to an answer like “dog, cat, lion, tiger, bear, wolf…”, etc. Like before, the general idea is that recall of each item derives from a random walk in a cognitive “memory space”, with emissions (usually) only when a new animal is encountered. A participant might have backtracked internally to <em>dog</em> from bear and jumped to wolf, for example.</p>
<p>Using a high-dimensional multilabel embedding space is possible, with one-column-per-animal, but the lists tend to be quite long and give networks with “hairball” tendencies. However, if our intention is to find <em>dependencies</em> between animals for a large number of participants, we might reasonably limit the co-occurrence to only a nearby subset of each list. Effectively, we can limit the set of possible co-occurring animals based on our domain knowledge, namely, the limits of working memory. Conservatively, with a well-cited work claiming 7 <span class="math inline">\(\pm\)</span> 2 semantic units at a time in working memory<span class="citation" data-cites="magicalnumberseven_Miller1956"><a href="#ref-magicalnumberseven_Miller1956" role="doc-biblioref">[3]</a></span>, we can limit the set of possible dependencies for a given item to the 5 items on either side. The 5 previous might have originated a jump to the current term, and the 5 after might be subsequent targets, for a <em>rolling window</em> of 10 terms at-a-time.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="ref-magicalnumberseven_Miller1956" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">G. A. Miller, <span>“The magical number seven, plus or minus two: Some limits on our capacity for processing information.”</span> <em>Psychological Review</em>, vol. 63, no. 2, pp. 81–97, Mar. 1956, doi: <a href="https://doi.org/10.1037/h0043158">10.1037/h0043158</a>.</div>
</div><div id="fn6"><p><sup>6</sup>&nbsp; This is precisely the logic that leads to the use of Skip-Gram and Continuous-Bag-of-Words transformations of text to weakly supervise word2vec and GloVe models<span class="citation" data-cites="GloveGlobalvectors_Pennington2014 Efficientestimationword_Mikolov2013"><a href="#ref-GloveGlobalvectors_Pennington2014" role="doc-biblioref">[26]</a>, <a href="#ref-Efficientestimationword_Mikolov2013" role="doc-biblioref">[27]</a></span>. </p><div id="ref-GloveGlobalvectors_Pennington2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">J. Pennington, R. Socher, and C. Manning, <span>“Glove: Global vectors for word representation,”</span> in <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em>, 2014, pp. 1532–1543.</div>
</div><div id="ref-Efficientestimationword_Mikolov2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">T. Mikolov, K. Chen, G. Corrado, and J. Dean, <span>“Efficient estimation of word representations in vector space,”</span> <em>arXiv preprint arXiv:1301.3781</em>, 2013.</div>
</div></div><div id="ref-Estimatingsemanticnetworks_Zemla2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">J. C. Zemla and J. L. Austerweil, <span>“Estimating semantic networks of groups and individuals from fluency data,”</span> <em>Computational brain &amp; behavior</em>, vol. 1, pp. 36–58, 2018, doi: <a href="https://doi.org/10.31234/osf.io/kg45r">10.31234/osf.io/kg45r</a>.</div>
</div></div><p>For our case study, we use lists of animals submitted by participants as described in <span class="citation" data-cites="semanticorganizationanimal_Goni2011 Estimatingsemanticnetworks_Zemla2018"><a href="#ref-Estimatingsemanticnetworks_Zemla2018" role="doc-biblioref">[9]</a>, <a href="#ref-semanticorganizationanimal_Goni2011" role="doc-biblioref">[25]</a></span>. We limit the animals under consideration to those that occurred in more than 30 lists for a good sample size, as well as lists with at least two animals. This resulted in 100 animals over 293 fluency lists. However, we ignore this filtering when creating the 10-animal rolling windows, to avoid inclusion of unrelated animals into prematurely filtered windows. After re-applying the filter, 100 animals appear across 8020 working-memory windows. <a href="#fig-fluency-workingmemory" class="quarto-xref">Figure&nbsp;<span>9.4</span></a> shows the effects of this preprocessing on marginal distributions.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-workingmemory">
<div id="cell-fig-fluency-workingmemory" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="33">
<div class="cell-output cell-output-display">
<div id="fig-fluency-workingmemory" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-workingmemory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-workingmemory-output-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-workingmemory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.4: Effects of rolling-window activations on observation data
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Doing this preprocessing (for rolling-windows of 10) shifts relative animal frequencies downward (since there are many more “observations” from the rolling window), while also shifting the number of animals-per-observation to be strictly less than 10. As desired, the pairwise cosine similarity of all vectors <span class="math inline">\(\mathbf{x}'_{j'},
\mathbf{x}'_{j}\)</span> is significantly reduced. While many participants might cover similar animals <em>overall</em>, we want to investigate animal dependencies locally, and we don’t expect individuals to always recall animals in the same memory “area” the whole time.</p>
</section>
<section id="sec-edge-diversity" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-edge-diversity">Edge Connective Efficiency and Diversity</h3>
<p>To compare the results of different backboning techniques, we introduce a new simple measure to quantify a network’s sparsity, in terms of how many edges more than <span class="math inline">\(n-1\)</span> (the minimum number needed to connect all <span class="math inline">\(n\)</span> nodes) are being used. <span id="eq-connect-efficient"><span class="math display">\[
\begin{gathered}
\psi_n(e) = \frac{e_{\text{min}}}{e}\frac{e_{\text{max}}-e}{e_{\text{max}}-e_{\text{min}}}\\
e_{\text{max}} = \frac{n(n-1)}{2} \quad e_{\text{min}} = n-1
\end{gathered}
\tag{9.3}\]</span></span></p>
<p>We call <span class="math inline">\(\psi\)</span> the graph’s “connective efficiency”, and it will range from 0 when the graph is fully connected, to 1 when it is a tree, to &gt;1 when it has insufficient edges to be connected. This measure is intended to compare graphs that have had edges removed until it is about to be disconnected, such as with the <em>Doubly Stochastic Filter</em> (DS) <span class="citation" data-cites="twostagealgorithm_Slater2009"><a href="#ref-twostagealgorithm_Slater2009" role="doc-biblioref">[28]</a></span>. However, values greater than 1 also give insight to how much sparser than a tree some graph is.</p>
<div class="no-row-height column-margin column-container"><div id="ref-twostagealgorithm_Slater2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">P. B. Slater, <span>“A two-stage algorithm for extracting the multiscale backbone of complex weighted networks,”</span> <em>Proceedings of the National Academy of Sciences</em>, vol. 106, no. 26, pp. E66–E66, Jun. 2009, doi: <a href="https://doi.org/10.1073/pnas.0904725106">10.1073/pnas.0904725106</a>.</div>
</div><div id="ref-semanticorganizationanimal_Goni2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">J. Goñi <em>et al.</em>, <span>“The semantic organization of the animal category: Evidence from semantic verbal fluency and network theory,”</span> <em>Cognitive processing</em>, vol. 12, no. 2, pp. 183–196, 2011.</div>
</div></div><p>The DS animal network is shown in <a href="#fig-fluency-dsmin" class="quarto-xref">Figure&nbsp;<span>9.5</span></a>. With large, deeply connected clusters centered around contexts animals are found in <a href="#fig-fluency-dsmin" class="quarto-xref">Figure&nbsp;<span>9.5</span></a> looks very similar to the network recovered to make Fig. 4 in <span class="citation" data-cites="semanticorganizationanimal_Goni2011"><a href="#ref-semanticorganizationanimal_Goni2011" role="doc-biblioref">[25]</a></span>. Clusters approximate animal types by their location relative to humans: farm/livestock, ocean/water creatures, “African” and jungle animals, small indoor mammals, small outdoor mammals, etc.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-dsmin">
<div id="cell-fig-fluency-dsmin" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="36">
<div class="cell-output cell-output-display">
<div id="fig-fluency-dsmin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-dsmin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-dsmin-output-1.svg" class="lightbox" data-gallery="fluency" title="Figure&nbsp;9.5: Verbal Fluency (animals) Network Backbone (Doubly-Stochastic)"><img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-dsmin-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-dsmin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.5: Verbal Fluency (animals) Network Backbone (Doubly-Stochastic)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>This is largely how the literature on semantic fluency leaves their network recovery solution, with clusters based on human proximity or physical location. However, there are other ways people might relate animals than simply by location. Additionally, clique bias is quite strong in this network: why must every farm animal be mutually connected if its possible to recall any of them through one or two “hub” animals? This is related to the incredible inefficiency of this backbone, with a <span class="math inline">\(\psi=0.35\)</span> being rather closer to fully connected than sparse. Additionally, the two animals that seem to appear <em>regardless</em> of others are <em>cat</em> and <em>dog</em>, which ironically makes DS penalize their proximity to any of the clusters. Both are ironically clustered with ocean animals due to their tendency to be listed near <em>fish</em>.</p>
<p>The Chow-Liu tree network is shown in <a href="#fig-fluency-tree" class="quarto-xref">Figure&nbsp;<span>9.6</span></a>, and goes some way to alleviating these issues. Clusters are largely intact, instead represented by large branches/subtrees off the main group. However, some community relationships have been sacrificed to maintain strong individual edges, such as <em>monkey</em>+<em>giraffe</em> for location similarity at the expense of separating two halves of the pink cluster across a wide distance. More alternate paths between creatures (i.e.&nbsp;loops) are needed to better represent our perception of animal relationships.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-tree">
<div id="cell-fig-fluency-tree" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="38">
<div class="cell-output cell-output-display">
<div id="fig-fluency-tree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-tree-output-1.svg" class="lightbox" data-gallery="fluency" title="Figure&nbsp;9.6: Verbal Fluency (animals) Dependency Network (Chow-Liu Tree)"><img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-tree-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.6: Verbal Fluency (animals) Dependency Network (Chow-Liu Tree)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The other dependency network recovery method is GLASSO, which we have similarly thresholded at the minimum-connected point. It only slightly improves on connective efficiency (<span class="math inline">\(\psi=0.44\)</span>), though the cliques are replaced with much more dispersed connections throughout the graph. We also see that reasonable inter-group connections are better represented, such as <em>rabbit</em>+<em>squirrel</em>, though <em>cat</em> and <em>dog</em> are still isolated due to overrepresentation throughout the dataset.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-glassomin">
<div id="cell-fig-fluency-glassomin" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="39">
<div class="cell-output cell-output-display">
<div id="fig-fluency-glassomin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-glassomin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-glassomin-output-1.svg" class="lightbox" data-gallery="fluency" title="Figure&nbsp;9.7: Verbal Fluency (animals) Dependency Network (GLASSO)"><img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-glassomin-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-glassomin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.7: Verbal Fluency (animals) Dependency Network (GLASSO)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Subjectively, the GLASSO network is still difficult for an analyst to synthesize into useful knowledge, with so many edges, while the DS network only really managed to communicate one “kind” of knowledge (the context clusters). We would ideally prefer a backbone that provides a wider diversity of important edge “types”, for an analyst to better understand the kinds of animal relationships humans perceive.</p>
<p>To illustrate this, we show the <em>Forest Pursuit</em>(FP) network in <a href="#fig-fluency-fpmin" class="quarto-xref">Figure&nbsp;<span>9.8</span></a>. It has also been filtered to minimum-connected, like DS and GLASSO, though in this case the connective efficiency to reach that threshold is a staggering <span class="math inline">\(\psi=0.88\)</span>.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-fpmin">
<div id="cell-fig-fluency-fpmin" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="41">
<div class="cell-output cell-output-display">
<div id="fig-fluency-fpmin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-fpmin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-fpmin-output-1.svg" class="lightbox" data-gallery="fluency" title="Figure&nbsp;9.8: Verbal Fluency (animals) Dependency Network (Forest Pursuit)"><img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-fpmin-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-fpmin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.8: Verbal Fluency (animals) Dependency Network (Forest Pursuit)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Unlike the other networks that push “generalist” nodes like <em>cat</em> and <em>dog</em> onto long, distant chains, those chains are used in the FP network to hold rare subgroups of clusters, treating them as “gated” by the prominent “hubs” of those groups. For example, <em>cat</em> is correctly linked to <em>mouse</em> and <em>lion</em> (in addition to <em>bird</em>), while <em>lemur</em> is pushed down a longer chain of primates, “gated” by <em>gorilla</em>. Similarly with <em>eel</em> through <em>lobster</em> and <em>crab</em>.</p>
<p>A much broader edge-type diversity is also made apprarent with many non-context-based relationships made obvious with the improved sparsity. An analyst has an easier job of creating “edge-type inventories”, making the FP backbone an excellent exploratory assistant: animals can be related because they are:</p>
<ul>
<li>Co-located</li>
<li>Taxonomically similar (<em>cheetah</em>+<em>leopard</em>)</li>
<li>Famous predator/prey pairs (<em>cat</em>+<em>mouse</em>)</li>
<li>Pop-culture references (<em>lion</em><span class="math inline">\(\rightarrow\)</span><em>tiger</em><span class="math inline">\(\rightarrow\)</span><em>bear</em>)<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></li>
<li>Similar in ecological niche/role (<em>koala</em>+<em>sloth</em>)</li>
<li>Related through conservation or public awareness (<em>panda</em>+<em>gorilla</em>)</li>
<li>etc.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Note that the dependency-based methods correctly interpred these three as <em>not</em> being mutually connected in a triad, but specifically with this ordering (<em>tiger</em> in the middle).</p></div></div><p>This is further reflected in how FP alters the way <em>centrality</em> measures behave. Replicating <a href="3-07-qualitative.html#fig-lesmis-centrality" class="quarto-xref">Figure&nbsp;<span>8.7</span></a> for these graphs, <a href="#fig-animal-centrality" class="quarto-xref">Figure&nbsp;<span>9.9</span></a> shows the change in rank across the top 15 animals for the DS, GLASSO, and FP networks.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-animal-centrality">
<div id="cell-fig-animal-centrality" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="44">
<div class="cell-output cell-output-display">
<div id="fig-animal-centrality" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-animal-centrality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-animal-centrality-output-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-animal-centrality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.9: Changes in animal centrality ranking for FP vs co-occurrence,GLASSO
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>The DS centrality finds the most densely connected clique and gives all of its members incredibly high values. Meanwhile, the none of the top 5 most common animals (<em>dog,cat,lion,tiger,bear</em>)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> have high centrality <em>at all</em>. Both GLASSO and DS have farm animals (<em>chicken,goat,cow</em>) as the most important, despite the idea that goat likely could be reached from e.g.&nbsp;<em>cow</em> quite often. FP adds more variety, giving hub-animals from different communities high centrality scores, each of which could lead to a variety of different paths. While subjective, the ranks from FP appear to be a more holistic inventory of “lynchpin” animals, which provide nearby coverage for a large amount of others.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;Interestingly, <em>dog</em> never appears in centrality measures, and <em>none</em> of the networks connect dog to any other animal than <em>cat</em>. Meanwhile, <em>wolf</em> is associated more with <em>fox</em>, <em>coyote</em>, <em>dingo</em>, etc., which are notably all predators of farm animals.<br>
With the primary community structures being what they are (context/location-based), it seems that humans tend to put dogs in a category all their own.</p></div></div></section>
<section id="thresholded-structure-preservation" class="level3">
<h3 class="anchored" data-anchor-id="thresholded-structure-preservation">Thresholded Structure Preservation</h3>
<p>Another beneficial feature of <em>Forest Pursuit</em> is how it fares under increased thresholding. Because co-occurrence methods prioritize cliques, those cliques will remain connected as other edges are removed, effectively destroying the global structure of the animal network past a certain threshold. As seen in <a href="#fig-fluency-preservation" class="quarto-xref">Figure&nbsp;<span>9.10</span></a>, in keeping only the top 2% of edges, they are used to connect separated islands of animal communities.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-preservation">
<div class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="45">
<div id="fig-fluency-preservation" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="45">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-preservation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-fluency-preservation-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fluency-preservation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-preservation-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-fluency-preservation">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fluency-preservation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) co-occurrence retains local communities at the cost of global structure
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-fluency-preservation-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fluency-preservation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-preservation-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-fluency-preservation">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fluency-preservation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) clique-bias correction preserves central structure by disconnecting rare nodes
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-preservation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.10: Differences in structural preservation with over-thresholding.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Meanwhile, the FP network is quite robust to this excessive thresholding, with the global structure preserved at 2%. The removed edges have simply detached some of the rarer animals from the network entirely. These isolates not only reflect a more metrologically-sound idea (that rarer nodes would be disconnected at higher certainty thresholds), but are also beneficial to analysts, since manually re-connecting isolates of rare animals is simpler than manually determining a global reconnection strategy for island groups.</p>
<!-- {{< embed ../codefigs/results.qmd#fig-fp-compare >}} -->
</section>
<section id="sec-fp-preprocess" class="level3">
<h3 class="anchored" data-anchor-id="sec-fp-preprocess">Forest Pursuit as Preprocessing</h3>
<p>Because <em>Forest Pursuit</em> creates a representation of the observed data in <em>edge space</em>, we can use <a href="../part2/2-05-forest-pursuit.html#eq-sparse-approx-tree" class="quarto-xref">Equation&nbsp;<span>6.4</span></a> in the forward direction, creating a “new”design matrix <span class="math inline">\(X\gets BR\)</span>. As discussed in <a href="../part2/2-05-forest-pursuit.html#sec-fp-problem" class="quarto-xref"><span>Problem Specification</span></a>, <a href="../part2/2-05-forest-pursuit.html#eq-sparse-approx-tree" class="quarto-xref">Equation&nbsp;<span>6.4</span></a> will create a design matrix of interaction counts for each node (its degree in the steiner tree approximation), rather than a binary “on/off” indicator.</p>
<p>By supplying <em>other algorithms</em> with this new estimate for <span class="math inline">\(X\)</span>, this makes FP a kind of preprocessing on the data itself. We can do this to bias the other methods toward greater sparsity in the backbone, without explicitly relying on point estimates for each observation (any tree with those node degrees would do the same). As shown in <a href="#fig-fluency-preprocess" class="quarto-xref">Figure&nbsp;<span>9.11</span></a>, GLASSO and DS both increase their connective efficiency under FP preprocessing.</p>
<div class="quarto-embed-nb-cell" data-notebook="/home/rtbs/syncthing/docs/professional/publications/thesis/dissertation/content/codefigs/qualitative.qmd" data-notebook-title="Source for Case Studies" data-notebook-cellid="cell-fig-fluency-preprocess">
<div class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="47">
<div id="fig-fluency-preprocess" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-execution_count="47">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fluency-preprocess-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-fluency-preprocess-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fluency-preprocess-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-preprocess-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-fluency-preprocess">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fluency-preprocess-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Doubly Stochastic filter with FP (node degree) preprocessing
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-fluency-preprocess-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fluency-preprocess-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="3-08-ordered_files/figure-html/..-codefigs-qualitative-fig-fluency-preprocess-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-fluency-preprocess">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fluency-preprocess-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) GLASSO Precision estimate with FP (node-degree) preprocessing
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fluency-preprocess-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.11: Forest Pursuit preprocessing for Doubly-Stochastic and GLASSO recovered networks
</figcaption>
</figure>
</div>
</div>
</div>
<p>This is likely due to the increase in “signal-to-noise” ratio for each datapoint, since observations are only similar when they have a node interacting the same “amount”, not merely when similar nodes are activated.</p>
<p>Because the entries are now integer counts, FP preprocessing might also give a better path to using distribution-based embedding and clustering techniques, such as Hellinger distances between multinomial sample counts. This goes for many other techniques from text processing that rely on multinomial assumptions (i.e.&nbsp;techniques otherwise inapplicable to binary data).<br>
FP Preprocessing, with further empirical and theoretical validation, might prove to be a powerful tool for practitioners to flexibly backbone and analyse their networks with a variety of new techniques.</p>



</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../../content/part3/3-07-qualitative.html" class="pagination-link" aria-label="Qualitative Application of Relationship Recovery">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Qualitative Application of Relationship Recovery</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../content/09-conclusion.html" class="pagination-link" aria-label="Conclusion &amp; Future Work">
        <span class="nav-page-text"><span class="chapter-title">Conclusion &amp; Future Work</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>