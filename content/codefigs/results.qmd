---
title: Source for results
html-table-processing: none
execute:
  cache: true
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: Python (Pixi)
    language: python
    name: pixi-kernel-python3
---

```{python}
import pandas as pd
import awkward as ak
import akimbo.pandas
import seaborn as sns
import seaborn.objects as so
# from great_tables import GT
import json
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as m
# from mendr.experiments import (
#     load_graph, _datasets#,_estimators, _metrics,_sq, _dataset_paths
# )
```

```{python}
m.rcParams['font.family']=['serif']
m.rcParams['font.serif']=['Bitstream Charter']
figsize = m.rcParams['figure.figsize']

plot_palette=sns.color_palette(['dodgerblue','xkcd:rust','#e6acca']) ##9d6784
sns_theme_kws = dict(
    font='serif',
    palette=plot_palette, 
    context='paper', 
    style='ticks'
)
sns.set_theme(**sns_theme_kws)

m.rcParams['savefig.transparent'] = True
m.rcParams["figure.facecolor"] = (1.0, 1.0, 1.0, 0.0) 
m.rcParams["axes.facecolor"] = (1.0, 1.0, 1.0, 0.0) 

%config InlineBackend.figure_formats = ['svg']
# list(Path('../results').glob('*.jsonl'))
my_orange=(231., 195., 138.)  # "#e7c38a"
my_green =(141., 203., 160.)  # "#8dcba0"
my_red   =(252.,  98., 142.)  # "#fc628e"
my_blue  =(171., 215., 230.)  # "#abd7e6"
my_grey = (200,200,200)

datapath = Path('../../data')
```

```{python}
from scipy.linalg import lstsq

def semilog_partial_residuals(df, algs, target, feats, fig=None):
    if fig is None: 
        f = m.figure.Figure()
    else: 
        f = fig
    
    sbplts = f.subplots(1, len(feats), sharey=True)
    for alg in algs:

        filt = df.query(f"name=='{alg}'")
        notna=filt[target].notna()
        y = filt[target].loc[notna].values
        
        x= filt[feats].loc[notna].values 
        M = np.c_[np.ones(x.shape[0]),np.log10(x)]
        p,res,rnk,s = lstsq(M,y)
        resid = y - M@p
        for i,feat in enumerate(feats):
            x = M[:,i+1]
            pred = x*p[i+1]
            sbplts[i].scatter( np.power(10,x),resid+pred,marker='.', alpha=0.2)
            x = np.linspace(x.min(), x.max())
            sbplts[i].plot( np.power(10,x),x*p[i+1], label=alg)
            

            sbplts[i].set(xlabel=feat,xscale='log')
    sbplts[0].set(ylabel=f'{target} (residual)')
    handles, labels = sbplts[0].get_legend_handles_labels()
    f.legend(handles, labels, loc='lower center', ncols=len(algs))
    f.subplots_adjust(bottom=0.25)
    return f
```

```{python}
df = pd.concat(
    [pd.read_json(p, lines=True) for p in datapath.glob('evaluations/*.jsonl')]
).replace(
    {'kind':['TR','BL','SC']}, value={'kind':['Tree','Block','ScaleFree']}
)#.assign()
# {'TR':'Tree','BL':'Block', 'SC':'ScaleFree'}
df
```

```{python}
# df.MCC.min()s
```

```{python}
def tidy_up(df, algs, graphs, metrics): 
    return (
        df
        # .drop(['thres-vals', 'F1','matthews_corrcoef', 'fowlkes_mallows'], axis=1)
        .melt(
            id_vars=['ID', 'kind','name','n-nodes','n-edges','n-walks','n-jumps',
                     'med-node-ct','iqr-node-ct','med-actv-ct','iqr-actv-ct',
                     'seconds'], 
            value_vars=['F-M','MCC','F1', 'APS'],
            value_name='score', var_name='metric'
        )
        .astype({
            'kind':'category', 
            'name':'category', 
            'metric': 'category',
            'ID':str,
        })
        .assign(**{
            # 'kind': lambda df: df['kind'].cat.rename_categories({'TR':'Tree','BL':'Block', 'SC':'ScaleFree'}),
            'seconds-log': lambda df: np.log10(df['seconds']),
            # 'jump-density':lambda df: df['n-jumps']/df['n-nodes'],
            'edge-density': lambda df: df['n-edges']/(df['n-nodes']*(df['n-nodes']-1)/2.),
            'edge-sparsity': lambda df: 1-df['edge-density'],
    
            'actv-fraction': lambda df: df['med-actv-ct']/df['n-nodes'],
            'node-baseprob': lambda df: df['med-node-ct']/df['n-walks'],
            # 'walk-density': lambda df: df['n-walks']/df['n-nodes'],
            # 'nodes-norm': lambda df: 1/df['walk-density'],
            # https://www.researchgate.net/publication/271685622_User%27s_Guide_to_Ratio_Variables
            'sec-per-walk': lambda df: df['seconds']/df['n-walks'],
            'logsec-per-walk': lambda df: np.log(df['sec-per-walk']),
            'node-exposure': lambda df: df['n-nodes']/df['n-walks'],
            'inv-walks': lambda df: 1/df['n-walks'],
            # 'jump-sparsity'
            'tot-jumps': lambda df: df['n-jumps']*df['n-walks'],
            'MIR': lambda df: 1/df[df.name.isin(algs)].groupby(['ID','metric'], observed=True)['score'].rank(ascending=False),
            'failed': lambda df: df['score'].isna()
        })
        
    )
```

```{python}
alg_order=['FP','GL','CS','HYP','eOT','HSS','RP']
graph_order=['Tree', 'Block', 'ScaleFree']
metric_order=['MCC','F-M','APS']

tidy = tidy_up(df, alg_order, graph_order, metric_order)
tidy.dtypes#.kind
# print(alg_order)
```

```{python}
tidy.query('metric=="APS"').groupby('name', observed=True)['score'].mean().sort_values(ascending=False)
```

```{python}
avg_scores= tidy.query('metric=="MCC"').groupby('name', observed=True)['score'].mean().sort_values(ascending=False)
avg_scores
```

```{python}
def compare_algs_single(tidy, alg_order,metric='MCC', **catplot_kws):
    defaults = dict(
        orient='h',
        # kind='box', 
        x='score',
        # estimator='median',
        # errorbar=('pi',50),
        # aspect=1.3, height=2,
        color='0.8',
        fliersize=1,
        gap=0.2
    )
    kws=defaults | catplot_kws
    return sns.boxplot(
        tidy.query('metric==@metric'), 
        y='name', 
        order=alg_order,
        **kws
    )
# sns.boxplot()
```

```{python}
#| label: fig-fp-overall
#| fig-cap: Comparison of MENDR recovery scores

"""
**FP**: Forest Pursuit 
**GL**: GLASSO
**CS**: Cosine Similarity 
**HYP**: Hyperbolic Projection
**eOT**: Entropic Optimal Transport (Doubly Stochastic)
**HSS**: High-Salience Skeleton
**RP**: Resource Projection
"""


f,ax = plt.subplots(ncols=3, figsize=((6,2.5)), sharey=True)
for a in ax: 
    a.axvline(0.5, color='0.9')
compare_algs_single(tidy, alg_order, ax=ax[0])
ax[0].set_xlabel('E[MCC]');

compare_algs_single(tidy, alg_order, metric='F-M', ax=ax[1])
ax[1].set_xlabel('E[F-M]');

compare_algs_single(tidy, alg_order, metric='APS', ax=ax[2])
ax[2].set_xlabel('APS');

plt.tight_layout()
sns.despine()
```

```{python}
def compare_algs(tidy,alg_order, graph_order,metric_order, **facet_kws): 
    defaults = dict(
        col="metric", row="kind",
        margin_titles=True, aspect=1, height=2,
        col_order=metric_order,
        row_order=graph_order,
    )
    kws = defaults | facet_kws
    g = sns.FacetGrid(
        tidy, 
        **kws
    )
    
    g.set(
        ylim=(-0.1,1.1), 
        clip_on=False,
    )
    # g.map(
    #     sns.pointplot, "score", "name", 
    #     order=alg_order,
    #     estimator='median',
    #     errorbar=None,
    #     linestyle='',
    #     color='r',
    #     marker='|',
    #     markersize=15,
    # )
    
    # g.map(
    #     sns.stripplot, "score","name",
    #     order=alg_order,
    #     dodge=True, alpha=.2, marker='.',
    #     color='grey',
    
    # )
    g.map(
        sns.boxplot, "score","name",
        order=alg_order,
        # dodge=True, alpha=.2, marker='.',
        # color='grey',
        color='0.8',
        fliersize=1,
        gap=0.3
    
    )
    return g
# sns.pointplot()
```

```{python}
#| label: fig-fp-compare
#| fig-cap: Comparison of MENDR Recovery Scores by Graph Type


g = compare_algs(tidy, alg_order, graph_order, metric_order,aspect=1)
```

```{python}
pd.concat([
    tidy.groupby(['metric','name'], observed=True)['score'].mean().unstack()[alg_order],#.round(2)
    tidy.groupby('name', observed=True)['MIR'].mean().to_frame().T[alg_order]
]).T.round(2)
```

```{python}
def plot_median(data, *args, **kwargs):
    # my = data[kwargs.get(y,data.columns[1])].median()
    # mx = data[kwargs.get(x,data.columns[1])].median()
    plt.axhline(data.median(), **kwargs)
    # plt.axvline(mx**kwargs)

def compare_scores_vs(tidy, xvar, alg_order=alg_order, metric='MCC'):
    return sns.FacetGrid(
        tidy.query(f'metric=="{metric}"'), 
        col="name",
        # col_wrap=3, 
        aspect=.8, height=2.,
        col_order=alg_order,
    ).map(
        plot_median,'score', 
        color='r', alpha=0.5, 
        clip_on=False, 
        label='median score'
    ).map(
        sns.regplot, xvar, "score", 
        color=".3", 
        logx=True, 
        scatter_kws={'alpha':0.2},
        line_kws={'ls':'--','color':'k','label':'OLS trend line'},
        marker='.', label='experiment',
    
    ).set(
        ylim=(-0.1,1.1), 
        # xlim=(0.09,11), 
        ylabel=metric,
        xscale="log", 
        clip_on=False
    )#.add_legend(
    #     loc=(0.6,0.15), ncols=1
    # )
```

```{python}
#| label: fig-mendr-trends
#| fig-cap: Score trends vs problem scaling
#| fig-subcap:
#|   - 'Trend: MCC vs network size'
#|   - 'Trend: MCC vs observation count'
#|   - 'Trend: MCC vs random-walk length'
compare_scores_vs(tidy,'n-nodes', metric='MCC', alg_order=['FP','GL','CS','HYP'])
compare_scores_vs(tidy,'n-walks', metric='MCC', alg_order=['FP','GL','CS','HYP'])
compare_scores_vs(tidy,'n-jumps', metric='MCC', alg_order=['FP','GL','CS','HYP'])
```

```{python}
#| label: fig-partials-mcc
#| fig-cap: Partial Residuals (regression on E[MCC])

f = plt.figure(figsize=(figsize[0], figsize[1]/1.8))
semilog_partial_residuals(
    df,
    ['FP','GL','CS'],
    'MCC',
    ['n-jumps', 'n-nodes','n-walks'],
    fig=f
);

# plt.gcf().suptitle('Partial Residuals, MCC')
```

```{python}
# compare_scores_vs(tidy,'edge-density', metric='MCC')
```

```python
g = sns.FacetGrid(
    tidy, row="metric", col="name",
    margin_titles=True, aspect=1, height=2,
    row_order=metric_order,
    col_order=alg_order,
    hue='metric',
    hue_order=metric_order,
    # hue = 'kind', 
    # hue_kws={
    #     'marker':['1','2'], 
    #     # 'line_kws':[{'color':sns.color_palette('dark')[0],'ls':':'},{'color':'sienna','ls':':'}]},
    # }
)
g.set(
    ylim=(-0.1,1.1),
    # xlim=(0.09,11), 
    xscale="log", 
    clip_on=False
)
g.map(plot_median, 'score', color='r', alpha=0.2)

g.map(
    sns.regplot, "med-node-ct", "score", 
    # color=".3", 
    logx=True, 
    scatter_kws={'alpha':0.5},
    # line_kws={'alpha':1.}
    line_kws={'ls':'--','color':'k'},
    marker='1',
    # marker='.'#,scatter_kws={'fillstyle':'none'}

)
g.add_legend()
```

```{python}
sns.boxplot(
    data=(tidy
     .pivot(index=['ID','metric'], columns='name', values='score')
     # .pipe(lambda df: df[['FP', 'FPi']].max(axis=1) - df['GL'])
     .pipe(lambda df: df['FP'] - df['GL'])

     .rename('score')
     .reset_index()
    ),
    x='score',
    y='metric'
);
```

```python
# ak.to_arrow(a).to_pandas()
# df.groupby(.pipe(lambda df: df.set_index('name').)
from sklearn.linear_model import LogisticRegression
from affinis.utils import _sq
from tqdm import tqdm
betas = []
diffs = []

dats = []
# df.query('name=="EFM"').estimate.ak.array- df.query('name=="FP"').estimate.ak.array
for dat in tqdm(_datasets): 
    df_sub = df.query(f'ID=="{dat}"').set_index('name')
    gT = _sq(load_graph(dat).graph.to_array().todense()).astype(bool)
    dats.append(gT)
    diff = np.array(df_sub.loc['EFM'].estimate)-np.array(df_sub.loc['FP'].estimate)
    diffs.append(diff)
    jitter_t = 0.2*np.random.rand(gT.sum())
    jitter_f = 0.2*np.random.rand((~gT).sum())
    # plt.scatter(diff[gT], np.ones_like(jitter_t)+jitter_t, color='k', alpha=0.1, marker='.')
    # plt.scatter(diff[~gT],np.zeros_like(jitter_f)+jitter_f, color='r', alpha=0.1, marker='.')

    betas+=[LogisticRegression(fit_intercept=False).fit(diff.reshape(-1,1), gT).coef_[0][0]]

delta = pd.DataFrame({'label':np.hstack(dats), 'diff':np.hstack(diffs)})
    # .estimate.ak.array- df.query('name=="FP"').estimate.ak.array
# df.query('name=="EFM"').estimate.ak.array- df.query('name=="FP"').estimate.ak.array
sns.displot(np.array(betas))
```

## Complexity and Runtime

```{python}
#| label: fig-runtime
#| fig-cap: Runtime Scaling (Forest-Pursuit vs GLASSO)

f = m.figure.Figure(figsize=(5,5))
sf1, sf2 = f.subfigures(2, 1, height_ratios=(1,1))
m.rcParams['font.family']=['serif']
m.rcParams['font.serif']=['Bitstream Charter']
theme_config = {**sns.axes_style('ticks')}|{
    "axes.spines.top": False, 
    "axes.spines.right": False,
    'font.family': 'serif',
    'font.serif': 'Bitstream Charter',
    'axes.facecolor': (1.,1.,1.,0.),
}

# med-node-ct','iqr-node-ct','med-actv-ct','iqr-actv-ct'

(so.Plot(tidy, x='n-nodes',y='seconds',color='name')
 # .add(so.Dots(marker='.'), so.Dodge(), so.Jitter(.3))
 # .add(so.Dots(alpha=0.1, pointsize=2), so.Dodge(gap=-.7), so.Jitter(0.1) )
 .add(so.Range(),so.Est(errorbar=("pi",95)), so.Dodge(gap=-1.7))
 .add(so.Dot(marker='o', pointsize=5), so.Agg('median'), so.Dodge())
 .scale(
     x=(so.Nominal()
        # .tick(at=[10,30,100,300])
        # .label(like="{x:.0f}")
       ), 
     y='log',
     # marker=so.Nominal(["_", "."]),
     # color=so.Nominal('Set2',order=['FP', 'EFM', 'GL'])
     color=so.Nominal(plot_palette[:-1],order=['FP', 'GL'])

 )
 .theme(theme_config)
 .on(sf1)
 .plot()
 # .add(so.Range(
)


p = (so.Plot(tidy, y='seconds',color='name',marker='failed', pointsize='failed', alpha='failed')
 .pair(x=['n-walks','n-jumps'])
 # .facet(row='name', order=['TS', 'GL','HSS'])
 .add(so.Dots(), so.Jitter(0.3))
 .scale(
     x='log', y='log',
     marker=so.Nominal([".", "x"]),
     # color=so.Nominal('Set2',order=['FP', 'EFM','GL']),
     color=so.Nominal(plot_palette[:-1],order=['FP','GL']),
     alpha=so.Nominal([1.,0.2]),
     pointsize=so.Nominal([2.,5.],order=[False,True]),
 )
 .theme(theme_config)
 .on(sf2)
 .layout(engine='constrained',extent=(0, 0, 0.95, 1))
 .plot()
 # .add(so.Line(color=".2"), so.PolyFit())
)
f.legends.pop(0)
# f.legends[0].get_bbox_to_anchor()#set_bbox_to_anchor((0.9,0.5)).
p
```

```python
g = sns.PairGrid(
    tidy[tidy['name'].isin(['FP'])], #row="metric", col="name",
    x_vars=['med-actv-ct', 'edge-density'],
    y_vars=['sec-per-walk'],
    hue = 'n-nodes', 
    palette='Set2',

)
g.set(
    # ylim=(-0.1,1.1), 
    # xlim=(0.09,11), 
    xscale="log", 
    yscale='log',
    clip_on=False,
)

g.map(
    sns.scatterplot, marker='.'#, logx=True, truncate=True,
)
g.add_legend()
```

```python
g = sns.relplot(
    tidy,
    # tidy.query("name in ['GL','TS']"),
    x='med-actv-ct',
    # x='med-node-ct',
    # x='jump-density',
    # y='seconds-log',
    # y='sec-per-walk',
    y = 'seconds',
    col='name',
    col_order=['FP','GL'], 
    hue='n-nodes', style='n-nodes',
    # markers=['+','.','x','s'],
    palette='Set2',
    # x_partial='n-nodes',
    # logx=True,
    # robust=True,
)
# ticks = 
# ax.get_yaxis().set_major_formatter(formatter)
# ax.get_yaxis().set_major_formatter(formatter)
g.set(
    xscale='log',
    # yticks=ticks,
    # xlabel='Activation Fraction',
    # ylabel='seconds',
    yscale='log',
    clip_on=False,
)
```

```{python}
def log_partial_residuals(df, algs, target, feats, fig=None):
    if fig is None: 
        f = m.figure.Figure()
    else: 
        f = fig
    
    sbplts = f.subplots(1, len(feats), sharey=True)
    for alg in algs:

        filt = df.query(f"name=='{alg}'")
        notna=filt[target].notna()
        y = filt[target].loc[notna].values
        
        x= filt[feats].loc[notna].values 
        M = np.c_[np.ones(x.shape[0]),np.log10(x)]
        p,res,rnk,s = lstsq(M,np.log10(y))
        resid = np.log10(y) - M@p
        for i,feat in enumerate(feats):
            x = M[:,i+1]
            pred = x*p[i+1]
            sbplts[i].scatter( np.power(10,x),np.power(10,resid+pred),marker='.', alpha=0.2)
            x = np.linspace(x.min(), x.max())
            sbplts[i].plot( np.power(10,x),np.power(10,x*p[i+1]), label=fr'{alg} ($\alpha={p[i+1]:.2f}$)')
            

            sbplts[i].set(xlabel=feat, yscale='log',xscale='log')
            
    ys=sbplts[0].get_ylim()
    slopes = np.array([
        [1,0.5],
        [1,1],
        [1,2],
        [1,3],
    ])
    unitslopes = (slopes.T/np.sqrt((slopes**2).sum(axis=1))).T
    exponents = [0.5,1.,2.,3.]
    exp_labs = ['n½','n','n²',"n³"]
    for s in sbplts:
        s.set_ylim(ys)
        s.set_box_aspect(1)
        s.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),
          ncol=1, fancybox=True, shadow=True)
        xmin,xmax=s.get_xlim()
        x = np.linspace(xmin, xmax)
        # inv = s.transData.inverted()
        # print(inv(unitslopes))
        magnitude=0.5*np.log10(xmax/xmin)
        for i,n in enumerate(exponents): 
            t = np.linspace(xmin, x[x**n<ys[1]][-1])
            f_t = t**n
            mins=np.log10(np.array([t[0],f_t[0]]))
            maxs=np.log10(np.array([t[-1],f_t[-1]]))
            # magnitude = 0.8*(maxs[0]-mins[0])
            displace_vecs = (maxs-mins)/np.sqrt(np.sum((maxs-mins)**2))
            newpos = np.power(10,mins+magnitude*displace_vecs)
            s.plot( t,f_t, color='k', alpha=0.1)
            s.annotate(
                exp_labs[i], xy=newpos, color='0.6',
                bbox=dict(
                        facecolor='white', 
                        linewidth=0,
                        boxstyle="square,pad=0"
                    )
                )
        
        
    sbplts[0].set(ylabel=f'{target} (residual)')

    f.subplots_adjust(bottom=0.25)
    return f
```

```{python}
#| label: fig-partials-runtime
#| fig-cap: Partial Residuals (regression on computation time)
f = plt.figure(figsize=(figsize[0]*1.2, figsize[1]))

f=log_partial_residuals(df, ['FP','GL'], 'seconds', ['n-jumps', 'n-nodes','n-walks'], fig=f)
# f.suptitle();
```

```{python}
f = m.figure.Figure(figsize=(8, 3))
# feats = ['n-walks','med-actv-ct', 'med-node-ct', 'n-nodes']
feats = ['n-jumps', 'n-nodes','n-walks']
# feats = ['n-walks', 'n-nodes']

sbplts = f.subplots(1, len(feats), sharey=True)
    # x=,

x= tidy.query("name=='FP'")[feats].values 
M = np.c_[np.ones(x.shape[0]),np.log10(x)]
# M = np.c_[np.ones(x.shape[0]),x]
y = tidy.query("name=='FP'")['seconds'].values
p,res,rnk,s = lstsq(M,np.log10(y))
# p,res,rnk,s = lstsq(M,y)
print(p)
# plt.scatter( tidy.query("name=='TS'")['med-actv-ct'],y-M@p, color='dodgerblue', marker='.')
resid = np.log10(y) - M@p
for i,feat in enumerate(feats):
    x = M[:,i+1]
    pred = x*p[i+1]
    sbplts[i].scatter( np.power(10,x),np.power(10,resid+pred), color='dodgerblue',marker='.', alpha=0.1)
    # sns.regplot(x=np.power(10,x), y=np.power(10,resid+pred), ax=sbplts[i], robust=True)
    x = np.linspace(x.min(), x.max())
    sbplts[i].plot( np.power(10,x),np.power(10,x*p[i+1]), color='dodgerblue')
    # sbplts[i].plot( np.power(10,x),np.power(10,x*p[i+1]*np.log(x*p[i+1])), color='0.8')

    sbplts[i].set_xscale('log')
    sbplts[i].set_yscale('log')
    sbplts[i].set_title(feat)
    # sbplts[i].scatter( tidy.query("name=='FP'")['med-actv-ct'],y-M@p+M[d:,2]*p[2], color='dodgerblue',marker='+')
# x = np.linspace(M[:,2].min(), M[:,2].max())

x= tidy.query("name=='GL'")[feats].values 
M = np.c_[np.ones(x.shape[0]),np.log10(x)]
# M = np.c_[np.ones(x.shape[0]),x]
y = tidy.query("name=='GL'")['seconds'].values
p,res,rnk,s = lstsq(M,np.log10(y))
# p,res,rnk,s = lstsq(M,y)
print(p)
# plt.scatter( tidy.query("name=='GL'")['med-node-ct'],np.power(10,y-M@p), marker='+')
# plt.scatter( tidy.query("name=='GL'")['med-actv-ct'],y-M@p,color='xkcd:rust', marker='.')
for i,feat in enumerate(feats):
    x = M[:,i+1]
    pred = x*p[i+1]
    resid = np.log10(y) - M@p
    sbplts[i].scatter( np.power(10,x),np.power(10,resid+pred),color='xkcd:rust',marker='.', alpha=0.1)
    # print(M)
    x = np.linspace(x.min(), x.max())
    sbplts[i].plot( np.power(10,x),np.power(10,x*p[i+1]), color='xkcd:rust')

    sbplts[i].plot( np.power(10,x),np.power(10,x/2), color='k', alpha=0.1)
    sbplts[i].plot( np.power(10,x),np.power(10,x), color='k', alpha=0.1)
    sbplts[i].plot( np.power(10,x),np.power(10,2*x), color='k', alpha=0.1)
    sbplts[i].plot( np.power(10,x),np.power(10,3*x), color='k', alpha=0.1)

    sbplts[i].set(
        xscale='log',
        yscale='log',
        xlabel=feat,
        ylim=(0.1,2e4)
    )
sbplts[0].set(ylabel='seconds (residual)')

f.legend([None,'FP',None, 'GL'],loc=(0.6,0.05), ncols=4)
plt.tight_layout()
f.subplots_adjust(bottom=0.3)
# sbplts[1].plot(np.power(10,x),np.power(10,linearithmic([0.8,0.65,0.5], x, np.zeros_like(x))))
# plt.scatter( tidy.query("name=='TS'")['med-node-ct'],np.power(10,y-M@p), marker='.')
f
```

```{python}
# https://doi.org/10.2307/2095384

f = m.figure.Figure(figsize=(8, 3))
feats = ['n-jumps', 'n-nodes','n-walks']
ratio_feats=[i+'/n-walks' for i in ['1']+feats]
sbplts = f.subplots(1, len(feats), sharey=True)
    # x=,

x= tidy.query("name=='FP'")[feats].values 
M = np.divide(np.c_[np.ones(x.shape[0]),x].T,x[:,-1]).T
logM=np.log10(M)
logM[:,-1]=1
# M = np.c_[np.ones(x.shape[0]),x]
y = tidy.query("name=='FP'")['seconds'].values/x[:,-1]
logy = np.log10(y)
p,res,rnk,s = lstsq(logM,logy)
# p,res,rnk,s = lstsq(M,y)
print(p)
# plt.scatter( tidy.query("name=='TS'")['med-actv-ct'],y-M@p, color='dodgerblue', marker='.')
for i,feat in enumerate(ratio_feats[:-1]):
    x = logM[:,i]
    pred = x*p[i]
    resid = logy - logM@p
    # resid=y/(M@p)
    sbplts[i].scatter( M[:,i],np.power(10,resid+pred), color='dodgerblue',marker='.', alpha=0.1)
    x = np.linspace(x.min(), x.max())
    sbplts[i].plot(np.power(10,x),np.power(10,x*p[i]), color='dodgerblue')

    # sbplts[i].scatter( tidy.query("name=='FP'")['med-actv-ct'],y-M@p+M[:,2]*p[2], color='dodgerblue',marker='+')

# plt.scatter( tidy.query("name=='TS'")['med-node-ct'],np.power(10,y-M@p), marker='.')


x= tidy.query("name=='GL'")[feats].values 
M = np.divide(np.c_[np.ones(x.shape[0]),x].T,x[:,-1]).T
logM=np.log10(M)
logM[:,-1]=1
# M = np.c_[np.ones(x.shape[0]),x]
y = tidy.query("name=='GL'")['seconds'].values/x[:,-1]
logy = np.log10(y)
p,res,rnk,s = lstsq(logM,logy)
# p,res,rnk,s = lstsq(M,y)
print(p)
# plt.scatter( tidy.query("name=='GL'")['med-node-ct'],np.power(10,y-M@p), marker='+')
# plt.scatter( tidy.query("name=='GL'")['med-actv-ct'],y-M@p,color='xkcd:rust', marker='.')
for i,feat in enumerate(ratio_feats[:-1]):
    x = logM[:,i]
    pred = x*p[i]
    resid = logy - logM@p
    sbplts[i].scatter(M[:,i],np.power(10,resid+pred),color='xkcd:rust',marker='.', alpha=0.1)
    
    x = np.linspace(x.min(), x.max())    
    sbplts[i].plot(np.power(10,x),np.power(10,x*p[i]), color='xkcd:rust')

    # sbplts[i].plot( np.power(10,x),np.power(10,x/3), color='k', alpha=0.1)
    # sbplts[i].plot( np.power(10,x),np.power(10,x/2), color='k', alpha=0.1)
    # sbplts[i].plot( np.power(10,x),np.power(10,x), color='k', alpha=0.1)
    # sbplts[i].plot( np.power(10,x),np.power(10,2*x), color='k', alpha=0.1)

    sbplts[i].set(
        xscale='log',
        yscale='log',
        xlabel=feat,
        ylim=(0.01,2e3)
    )

sbplts[0].set(ylabel='seconds/walk (residual)')

    # sbplts[i].set_ylim(-0.5,0.5)
# print(res)
f.legend([None,'FP',None, 'GL'],loc=(0.6,0.05), ncols=4)
plt.tight_layout()
f.subplots_adjust(bottom=0.3)
f
```

## Interaction Probability for APS

```{python}
# GT=ak.from_json(Path('../../data/GroundTruth.jsonl'), line_delimited=True)
```

```{python}
# si = ak.zip({
#     'FPi':df.query('name=="FP"')['estimate'].ak.array*df.query('name=="CoOc"')['estimate'].ak.array,
#     'EFMi':df.query('name=="EFM"')['estimate'].ak.array*df.query('name=="CoOc"')['estimate'].ak.array,
#     'ground':GT,
# }, depth_limit=1)
```

```{python}
#| label: tbl-fpi
#| tbl-cap: Comparing scores for FP, FPi and GLASSO


from IPython.display import Markdown
from tabulate import tabulate
from great_tables import GT, md, html, style, loc
int_tidy = tidy_up(df, ['FP', 'FPi', 'GL'], graph_order, metric_order)

fpi_tbl = pd.concat([
    # int_tidy.groupby(['metric','kind','name'], observed=True)['score'].mean().unstack()[['FP','FPi','GL']],#.round(2)
    # int_tidy.groupby(['kind','name'], observed=True)['MIR'].mean().to_frame().T[['FP','FPi','GL']]
    int_tidy.groupby(['kind','metric','name'], observed=False)['score'].mean().unstack()#.loc[['FP', 'FPi', 'GL']],
    # int_tidy.groupby(['name','kind'], observed=True)['MIR'].mean().to_frame().loc[['FP','FPi','GL']]

], axis=1).round(2).swaplevel().sort_index()[['FP', 'FPi', 'GL']].reset_index().query('metric in @metric_order');#[metric_order]#.to_markdown()

# from IPython.display import Markdown

# Markdown(tabulate(fpi_tbl, tablefmt='github', headers=metric_order))
tab = GT(fpi_tbl,rowname_col="metric", groupname_col="kind")
tab.opt_table_font(
    font='Bitstream Charter'
).tab_style(
        style=
            [ style.fill(color="rgba(0, 0, 0, 0)")], locations=loc.body()
).tab_options(
    table_background_color='white',
    table_body_vlines_color='white',
    table_body_hlines_color='white',
).opt_vertical_padding(scale=0.6).show();

# fpi_tbl
# pd.DataFrame.to_markdown
# fpi_tbl.to_markdown()
```

```{python}
# for dat in si:
#     M = Contingent.from_scalar(ak.to_numpy(dat['ground']), ak.to_numpy(dat['FPi']))
#     print(_metrics['APS'](M))
    # print(M.mcc)
    # print(M.)
```

```{python}
compare_algs(int_tidy, ['FP','FPi','GL'], graph_order, metric_order,height=1.3, aspect=1.2)
# sns.FacetGrid()
# plt.tight_layout()
```

```{python}
#| label: fig-fpi
#| fig-cap: FPi shows best APS, lower MCC,F-M

f,ax = plt.subplots(nrows=3, figsize=((2.5,6)), sharey=True)
compare_algs_single(int_tidy, ['FP','FPi','GL'], metric='MCC', ax=ax[0])
ax[0].set_xlabel('E[MCC]');
compare_algs_single(int_tidy, ['FP','FPi','GL'], metric='F-M', ax=ax[1])
ax[1].set_xlabel('E[F-M]');
compare_algs_single(int_tidy, ['FP','FPi','GL'], metric='APS', ax=ax[2])
plt.xlabel('APS');
plt.tight_layout()
```

```{python}
# compare_algs_single(int_tidy,  ['FP','FPi','GL'], x='MIR')
# plt.xlabel('median MIR');
```

```{python}
semilog_partial_residuals(
    df,
    ['FP','GL','FPi'],
    'APS',
    ['n-jumps', 'n-nodes','n-walks']
)
```

## Expected Forest Max. 

```{python}
df_improv = pd.DataFrame([
    tidy.pivot(index=['ID','metric'], columns='name', values='score').pipe(lambda df: df['EFM']>df['FP']).rename('score-better'),
    tidy.pivot(index=['ID','metric'], columns='name', values='seconds').pipe(lambda df: df['FP']>df['EFM']).rename('time-better')
]).T.reset_index().query("metric=='MCC'")
df_improv
#pd.crosstab(df_improv['ID'], [df_improv['score-better'], df_improv['time-better']]).sum(axis=0).unstack()
```

```{python}
#| label: fig-efm-mcc
#| fig-cap: Change in Expected MCC (EFM vs FP)
sns.displot(
    data=(tidy.query('metric=="MCC"')
     .pivot(index=['ID','metric'], columns='name', values='score')
     .pipe(lambda df: df['EFM']-df['FP'] )
     .rename('score')
     .reset_index()
     .assign(improved=lambda df: df['score']>=1)
    ),
    x='score',
    color='0.7',
    # hue='improved',
    # log_scale=True,
    # stat='density',
    kind='hist',
    aspect=1.618,
    height=2,
    # y='metric'
)
plt.axvline(0, color='k')
plt.xlabel('E[MCC|EFM]-E[MCC|FP]');
# tidy.query('metric=="MCC"')
# plt.yscale('log')
```

```{python}
#| label: fig-efm-logits
#| fig-cap: Logistic Regression Coef. (EFM - FP) vs. (Ground Truth)

"""
Logistic regression coefficients for true edges via difference in EFM and FP scores. 
L2-regularization for overfit prevention was chosen with 5-fold cross validation, each time. 
"""
logits = (
pd.read_csv(datapath/'efm-fp-logodds.csv')
 .assign(
     kind=lambda df: df['dataset'].str[:2],
     OR=lambda df: np.exp(df['log-odds']),
 )
 .replace(
    {'kind':['TR','BL','SC']}, value={'kind':['Tree','Block','ScaleFree']}
 )
    
)

# sns.catplot()
f,ax = plt.subplots(nrows=2, sharex=True, height_ratios=(1,1), figsize=(figsize[0]*0.6, figsize[1]*0.6))
# sns.swarmplot(data=logits, y='kind', x='log-odds', orient='h', hue='kind', 
#               size=3,log_scale=True, ax=ax[0])
sns.histplot(data=logits,x='log-odds', log_scale=True, ax=ax[0], color='0.7')

# datapath
# sns.histplot(data=logits,x='log-odds', log_scale=True, hue='kind',multiple='fill')
sns.boxplot(data=logits,y='kind',x='log-odds', log_scale=True, ax=ax[1], color='0.7')

sns.despine()
ax[1].set_xlabel('Log-Odds-Ratio');
# ax[1].set_ylabel('Count Fraction')
# f.suptitle('');
# logits.columns#['log-odds']
```

```{python}
compare_algs_single(int_tidy, ['EFM','FP','GL'])
plt.xlabel('avg. E[MCC]');
```

```{python}
#| label: fig-efm-runtime
#| fig-cap: Runtime Scaling (Forest-Pursuit vs GLASSO)

f = m.figure.Figure(figsize=(5,5))
sf1, sf2 = f.subfigures(2, 1, height_ratios=(1,1))
m.rcParams['font.family']=['serif']
m.rcParams['font.serif']=['Bitstream Charter']
theme_config = {**sns.axes_style('ticks')}|{
    "axes.spines.top": False, 
    "axes.spines.right": False,
    'font.family': 'serif',
    'font.serif': 'Bitstream Charter',
    'axes.facecolor': (1.,1.,1.,0.),
}

# med-node-ct','iqr-node-ct','med-actv-ct','iqr-actv-ct'

(so.Plot(tidy, x='n-nodes',y='seconds',color='name')
 # .add(so.Dots(marker='.'), so.Dodge(), so.Jitter(.3))
 # .add(so.Dots(alpha=0.1, pointsize=2), so.Dodge(gap=-.7), so.Jitter(0.1) )
 .add(so.Range(),so.Est(errorbar=("pi",95)), so.Dodge(gap=-1.7))
 .add(so.Dot(marker='o', pointsize=5), so.Agg('median'), so.Dodge())
 .scale(
     x=(so.Nominal()
        # .tick(at=[10,30,100,300])
        # .label(like="{x:.0f}")
       ), 
     y='log',
     # marker=so.Nominal(["_", "."]),
     # color=so.Nominal('Set2',order=['FP', 'EFM', 'GL'])
     color=so.Nominal(plot_palette,order=['FP', 'GL', 'EFM'])

 )
 .theme(theme_config)
 .on(sf1)
 .plot()
 # .add(so.Range(
)


p = (so.Plot(tidy, y='seconds',color='name',marker='failed', pointsize='failed', alpha='failed')
 .pair(x=['n-walks','n-jumps'])
 # .facet(row='name', order=['TS', 'GL','HSS'])
 .add(so.Dots(), so.Jitter(0.3))
 .scale(
     x='log', y='log',
     marker=so.Nominal([".", "x"]),
     # color=so.Nominal('Set2',order=['FP', 'EFM','GL']),
     color=so.Nominal(plot_palette,order=['FP','GL', 'EFM']),
     alpha=so.Nominal([1.,0.2]),
     pointsize=so.Nominal([2.,5.],order=[False,True]),
 )
 .theme(theme_config)
 .on(sf2)
 .layout(engine='constrained',extent=(0, 0, 0.95, 1))
 .plot()
 # .add(so.Line(color=".2"), so.PolyFit())
)
f.legends.pop(0)
# f.legends[0].get_bbox_to_anchor()#set_bbox_to_anchor((0.9,0.5)).

p
```

```{python}
#| label: fig-efm-partials-runtime
#| fig-cap: Partial Residuals (regression on computation time)
f = plt.figure(figsize=(figsize[0], figsize[1]/1.8))

f=log_partial_residuals(df, ['FP','GL','EFM'], 'seconds', ['n-jumps', 'n-nodes','n-walks'], fig=f)
```
