---
title: Source for Case Studies
execute:
  cache: true
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: Python (Pixi)
    language: python
    name: pixi-kernel-python3
---

```{python}
import awkward as ak
from ruamel.yaml import YAML
from pathlib import Path 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import affinis.associations as asc
from affinis.utils import _sq
from affinis.filter import min_connected_filter,edge_mask_to_laplacian
from affinis.proximity import sinkhorn, forest_correlation
from affinis.distance import generalized_graph_dists, adjusted_forest_dists
import scipy.sparse as sprs

import numpy as np
import networkx as nx
```

```{python}
yaml = YAML(typ='safe')
# data = yaml.load(path)
datadir = Path('../../data/')

# s = ak.from_iter(yaml.load(datadir/'complex-networks.yaml').items())
# s = ak.Array(dict(zip(['id','meta'], ak.unzip(s))))
# ak.from_json()

df1 = (
    pd.DataFrame
    .from_dict(
        yaml.load(datadir/'complex-networks.yaml'), 
        orient='index'
    )
    .rename_axis('id')
)
df2 = (
    pd.DataFrame
    .from_dict(
        yaml.load(datadir/'complex-networks-struc-dyn.yaml'), 
        orient='index'
    )
    .rename_axis('id')
)
df = pd.concat([df1, df2])
df = df[~df.index.duplicated(keep='last')]
```

```{python}
# (~df2.index.isin(df1.index)).sum()

# df[df.index.duplicated(keep=False)]
```

```{python}
# ak.to_dataframe(s)
tidy=(df
 .explode('author')
 .reset_index()
 .assign(
     coauth=1,
     author=lambda df: (
         df.author
         .str.lower()
         .astype('category')
     )
 )
 # .set_index(['id','author'])
 # ['coauth'].unstack().fillna(0)
)
authortype=tidy['author'].dtype#.categories
# tidy.iloc[tidy.set_index(['id','author']).index.duplicated()]
# df.loc['WOS:000226704200004']
```

```{python}
Xdf = (
    tidy
    .set_index(['id','author'])
    ['coauth'].unstack().fillna(0)
)

Xdf = Xdf[Xdf.sum(axis=1)>1]
Xdf = Xdf.loc[:,Xdf.sum()>0]
Xdf = Xdf[Xdf.sum(axis=1)>1]

X = Xdf.values#.astype(bool)
Xdf.columns
```

```{python}
np.isin('barabási, a.', Xdf.columns)
```

```{python}
Xhyp = (Xdf.T/(Xdf.sum(axis=1)-1)).T

Xhyp.T@Xhyp - np.diag(np.diag(Xhyp.T@Xhyp))#-np.diag(Xhyp.sum())
```

```{python}
sns.histplot(Xdf.sum())
plt.yscale('log')
```

```{python}
sns.histplot(Xdf.sum(axis=1))
```

```{python}
# sns.heatmap(Xdf.T@Xdf - np.diag(Xdf.sum()))
```

```{python}

G = nx.from_pandas_adjacency((Xdf.T@Xdf - np.diag(Xdf.sum()))>0)

subset = sorted(nx.connected_components(G), key=len, reverse=True)[0]
# G = nx.from_pandas_adjacency((Xhyp.T@Xhyp - np.diag(np.diag(Xhyp.T@Xhyp)))>0.1)
# list(nx.neighbors(G, 'newman, m.'))
for k,subs in enumerate(sorted(nx.connected_components(G), key=len, reverse=True)): 
    if 'newman, m.' in subs: 
        print('newman',k)
# 'barabási, a.' in subset
    if 'sneppen, k.' in subs:
        print('sneppen',k)
```

```{python}
plt.figure(figsize=(25,25))
G = G.subgraph(subset)
pos_cos = nx.kamada_kawai_layout(G)
nx.draw_networkx(G, pos=pos_cos, node_color='w')
# nx.connected.is_connected(G)
print(len(subset))
```

```{python}
# subset
```

```{python}
# sns.heatmap(asc.ochiai(Xdf.values, pseudocts='min-connect')>0.5)

plt.figure(figsize=(25,25))
G = nx.from_pandas_adjacency(pd.DataFrame(asc.chow_liu(X, pseudocts=0.5), index=Xdf.columns, columns=Xdf.columns))
G = G.subgraph(subset)

pos_tree = nx.kamada_kawai_layout(G)
nx.draw_networkx(G, pos=pos_tree, node_color='w')
```

```{python}
(X.sum(axis=1)==0).sum()
```

```{python}
plt.figure(figsize=(25,25))
evd_L_pursuit = _sq(asc.forest_pursuit_edge(sprs.csr_array(X), pseudocts=('zero-sum','min-connect')))

G = nx.from_pandas_adjacency(pd.DataFrame(_sq(evd_L_pursuit>0.01), index=Xdf.columns, columns=Xdf.columns))
# G = nx.from_pandas_adjacency(pd.DataFrame(_sq(~min_connected_filter(evd_L_pursuit).mask), index=Xdf.columns, columns=Xdf.columns))

G = G.subgraph(subset)
pos = nx.kamada_kawai_layout(G)
nx.draw_networkx(G, pos=pos, node_color='w')
nx.connected.is_connected(G)
```

```{python}
# L = edge_mask_to_laplacian(np.ma.masked_less_equal(evd_L_pursuit, 0.01))
L = nx.laplacian_matrix(G, nodelist=list(subset))
# sns.clustermap(pd.DataFrame(forest_correlation(L),  index=list(subset), columns=list(subset)))
from sklearn.cluster import AgglomerativeClustering
sns.histplot(_sq(adjusted_forest_dists(L, beta=1000)))
```

```{python}
from scipy.cluster.hierarchy import dendrogram

clust=AgglomerativeClustering(
    metric='precomputed', linkage='complete',#, distance_threshold=0.2,
    distance_threshold=4, n_clusters=None
).fit(adjusted_forest_dists(L.todense(), beta=100))

def plot_dendrogram(model, **kwargs):
    # Create linkage matrix and then plot the dendrogram

    # create the counts of samples under each node
    counts = np.zeros(model.children_.shape[0])
    n_samples = len(model.labels_)
    for i, merge in enumerate(model.children_):
        current_count = 0
        for child_idx in merge:
            if child_idx < n_samples:
                current_count += 1  # leaf node
            else:
                current_count += counts[child_idx - n_samples]
        counts[i] = current_count

    linkage_matrix = np.column_stack(
        [model.children_, model.distances_, counts]
    ).astype(float)

    # Plot the corresponding dendrogram
    dendrogram(linkage_matrix, **kwargs)
plot_dendrogram(clust)
```

```{python}
# np.array(pal)[clust.labels_]
# clust.children_
clust.labels_
```

```{python}
pal = sns.color_palette(n_colors=clust.labels_.max()+1)
sns.clustermap(adjusted_forest_dists(L, beta=100), row_colors=np.array(pal)[clust.labels_])
```

```{python}
plt.figure(figsize=(25,25))
nx.draw_networkx(G, pos=pos, node_color='w')
nx.draw_networkx_labels(G, pos=pos, font_color=dict(zip(list(subset), np.array(pal)[clust.labels_])));
```

