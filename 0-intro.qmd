# Introduction

A wide variety of fields show consistent interest in inferring latent network structure from observed interactions, from human cognition and social infection networks, to marketing, traffic, finance, and many others. [@Inferringnetworksdiffusion_GomezRodriguez2012]
However, an increasing number of authors are noting a lack of agreement in how to approach the metrology of this problem. 
This includes rampant disconnects between the theoretical and methodological network analysis sub-communities[@Statisticalinferencelinks_Peel2022], treatment of error as purely aleatory, rather than epistemic [@Measurementerrornetwork_Wang2012], or simply ignoring measurement error in network reconstruction entirely[@ReconstructingNetworksUnknown_Peixoto2018].

To begin adressing these issues, this introductory section returns to foundational statistical measurment concepts and terminology, while clarifying each concepts potential relationships to the problems of network structure metrology.  
First, what "measurement" means in this context, and specifically the ways we encode observations, operations, and uncertainties numerically.
Second, what "relation" means, since network structure is intended to encode such relations as a mathematical object, despite common ambiguities and confusion around what practitioners intend on communicating through them. 


## Measuring relations through observation

Networks in the "wild" rarely exist of and by themsleves. 
Rather, they are a model of interaction or relation _between_ things that were observed. 
One of the most beloved examples of a network, the famed _Zachary's Karate Club_[CITE], is in fact reported as a list of pairwise interactions: every time a club member interacted with another (outside of the club), Zachary recorded it as two integers (the IDs of the members).
The final list of pairs can be _interpreted_ as an "edge list", which can be modeled with a network: a simple graph.
This was famously used to show natural community structure that nicely matches the group separation that eventually took place when the club split into two. 

Note, however, that we could have just as easily taken note of the instigating student for each interaction (i.e. which student initiated conversation, or invited the other to socialize, etc.).
If that relational asymmetry is available, our "edges" are now _directed_, and we might be able to ask questions about the rates that certain students are asked vs. do the asking, and what that implies about group cohesion.
Additionally, the time span is assumed to be "for the duration of observation" (did the students _ever_ interact), but if observation time was significantly longer, say, multiple years, we might question the credulity of treating a social interaction 2 years ago as equally important to an interaction immediately preceding the split.
This is now a "dynamic" graph; or, if we only measure relative to the time of separation, at the very least a "weighted" one.  

Where metrology is concerned, the actual unit of observation and how it is encoded for us is critical to how analysts may proceed with quantifying, modeling, and measuring uncertainty around observed phenomena. 

### Observation and Feature "Spaces"

Experiment and observation tends to be organized as inputs and outputs, or, independent variables and dependent variables, specifically.
Independent variables are observed, multiple times ("observations"), and changes in outcome can be compared to the varying values associated with the input ("features")
The structure most often used to record observational data on the independent/input variables is as a design matrix $X$.
In this scheme, a "data point" $\mathbf{x}_i=\left(X_{i1}, X_{i2}, \cdots X_{ik}\right)$ is a vector having some number $m$ of features that assign values to each of the relevant independent variables.
$X_{ij}$ is the measured value of the $j$th independent variable on the $i$th observation.^[
  There are various techniques for dealign with e.g. categorical data, such as one-hot encoding (where $k$ is the number of possible categories, with boolean entries for each feature)
]
Thus a single observation can be thought to exist at some coordinate in $m$-dimensional space, known as the _feature space_.
Importantly for the use of linear algebra, these values assigned for each feature are assumed to exist in a field (or, more generally, a semiring) $R$, equipped with operators analogous to addition ($\oplus$) and multiplication ($\otimes$) that allow for values to be aggregated through an inner product.
The matrix of all pairs of inner-products found by matrix multiplication (contracting over the feature space) is given by:

$$G(\mathbf{x}_i, \mathbf{x}_j,R) = G_{ij} = \bigoplus_{k=1}^{n} x_{ik} \otimes x_{kj} $$

such that real-valued entries and a traditional "plus-times" inner product recovers the Gram matrix $G_{ij}=\sum_{k=1}^{n} x_{ik}x_{kj}$, or simply $G=X^TX$.  

A collection of $n$  data points over a semiring , then, is represented by a so-called "design" matrix over a ring $X\in\mathcal{M}_{n\times k}(R)$, such that each row corresponds to one observation and each column reflects the location of every observation along that feature's coordinate.^[
  Sometimes vectors are said to form the column-space of a matrix, especially when using them as transformations in physics or deep learning layers. We generally follow a one-observation-per-row rule, unless otherwise stated
]
Note that this definition admits symmetry in application.
In other words, we could treat each observation as an independent variable, such that  each original "feature" (column) is itself a vector with independent variables being the state of each original "observation".
These are valid vectors over the same field/semiring, but now in an $n$-dimensional space we will call the _ data points (rows), i.e. the or "observation space".
The observation space will also have a well-defined inner-product. 

To illustrate this, let's take another classic network example from academia: co-citation networks.
List of co-authors on publications is often reported as "network" data, and subjected to network analysis techniques.
For each paper, some subset of known authors are all "active" participants. However, we are not given information about which author was invited by which other one, or when each author signed on.
In fact, this lack of pairwise information is a good reason to call such activation-type data _bipartite_, since we can represent our data as a bipartite graph, with $n$ papers and $k$ authors being bipartite sets, and a paper is connected to an author if that author was listed on that paper.
As a matrix, we could represent this as $X\in\mathcal{M}_{n\times k}(\mathbb{B})$, so that every paper is a vector on the boolean semiring.
The inner product between two papers will yield a "true" only if two papers share at least one author in common. 
This is called a _bipartite projection_[CITE], specifically the "papers" projection. 

Similarly, if our goal is to determine a network of "whether two authors ever coauthored", we could perform a bipartite projection using the boolean inner product in the observation space i.e. the "authors" projection.
It is this second projection, for determining a structure between features embedded into the  "observation" space, that we are primarily concerned with in this work, since it is the view that most closely resembles the concept of covariance or correlation between independent variables (features) in statistics more generally. 


### Model, Data, & Linear Operators

Forward model/operator maps model into data space, vs. Adjoint Model/Operator maps data into model space.
Inverse problems involve removing the effect of the operator $A$ from the data $y$  to recover the model $x$. 

### Measurement Quantification & Error 

- type I and II Error
- Epistemic and Alleatoric Uncertainty

Ultimately we are not great at specifying what "being related" actually means...


## What does "relation" mean?

### Incidence & Dependency

foundational model of graph theory and incidence structures more broadly.
More to come, but get the terminology down.

Spring example, road example, etc.
Discuss Complex Systems and their representation. 


### Proximities, Distances, & Kernels 

How "close" or "far away" things are.... Avrachenkov et al. 


Important: these measurements often assume distance is defined in terms of the measurements/objects/data, but for _inverse problems_, structure learning, etc., they are more often applied in terms of the features/operators.

Example with doc-term matrices 

### Ambiguity or Causality
Usually dependencies are taken as causing or enabling proximity.
E.g. shortest paths, vs. edges.


The approach taken by researchers/investigators...do they assume a level of interchangeability between the two kinds of "relation"?
Do they define
Or do they 
